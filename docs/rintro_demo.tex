% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Introduction to R for Advanced Research Methods (PS6183)},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Introduction to R for Advanced Research Methods (PS6183)}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter{\texorpdfstring{\textbf{Overview}}{Overview}}\label{overview}

\textbf{Authors:} Dr Ryan Donovan and Dr Ciara Egan.

This is the textbook for the Advanced Research Methods module (PS6183).
This textbook will describe how to use R programming language to import, clean, process, and visualise psychological data.
No prior knowledge of R or any other programming language or statistical software is required to successfully complete this module.

This textbook is still undergoing development and is not the final product.
Consequently, all textbook materials are used for educational purposes only and should only be shared within the University of Galway's School of Psychology.
Any issues or errors with the textbook should be reported to Ryan Donovan (ryan.donovan@universityofgalway.ie).

\section{What will I learn in R?}\label{what-will-i-learn-in-r}

In terms of specific R skills, students will learn how to:

\begin{itemize}
\item
  Import, export, and create datasets.
\item
  Use basic programming concepts such as data types, functions, and loops.
\item
  Apply key techniques for data cleaning to enable statistical analysis.
\item
  Run descriptive and inferential statistics.
\item
  Create APA-standard graphs.
\item
  Deal with errors or bugs with R code.
\end{itemize}

\section{What will I not learn to do in R?}\label{what-will-i-not-learn-to-do-in-r}

This is not an exhaustive introduction to R.
Similar to human languages, programming languages like R are vast and will take years to master.
After this course, you will still be considered a ``newbie'' in R.
But the material covered here will at least provide you a solid foundation in R, enabling you to go ahead and pick up further skills if required as you go on.

This course will teach you data cleaning and wrangling skills that will enable you to wrangle and clean a lot of data collected on Gorilla or Qualtrics.
But you will not be able to easily handle all data cleaning problems you are likely to find out in the ``wild'' world of messy data.
Such datasets can be uniquely messy, and even experienced R programmers will need to bash their head against the desk a few times to figure out a way to clean that dataset entirely in R.

Similarly, do not expect to be fluent in the concepts you learn here after these workshops.
It will take practice to become fluent.
You might need to refer to these materials or look up help repeatedly when using R on real-life datasets.
That's normal - so do not be discouraged when it happens.

This textbook mainly uses the tidyverse approach to R.
The tidyverse is a particular philosophical approach to how to use R (more on that later).
The other approach would be to use base R.
This can incite violent debates in R communities on which approach is better.
We will focus mainly on tidyverse and use some base R.

This textbook does not teach you how to use R Markdown.
R Markdown is a package in R that enables you to write reproducible and dynamic reports with R that can be converted into Word documents, PDFs, websites, PowerPoint presentations, books, and much more.
There are a lot of excellent resources available to learn how to use R markdown, but it's far more important to learn how to use R first.

\section{Why are we learning R?}\label{why-are-we-learning-r}

There are many reasons to learn R.

Psychological research is increasingly moving towards open-science practices.
One of the key principles of open-science is that all aspects of data handling - including data wrangling, pre-processing, processing, and output generation - are openly accessible.
This is not just an abstract ideal; several top-tier journals require that you submit R scripts along with manuscripts.
If you don't know how to use R (or at least no one in your lab does), then this puts you at a disadvantage.
The upside to this is that if you do know how to use R, then you will be at an advantage in your future career prospects.

R enables you to import, clean, analyse, and publish manuscripts from R itself.
You do not have to switch between SPSS, Excel, and Word or any other software.
You can conduct your statistical analysis directly in R and have that ``uploaded'' directly to your manuscript.
In the long run, this will save you significant time and energy.

R is capable of more than statistical analysis.
You can create websites, documents, and books in R.
This e-book was developed in R!
We will talk more in class about the advantages of using R over existing propriety statistical software.

\section{Where and when will the classes take place?}\label{where-and-when-will-the-classes-take-place}

The sessions will take place in \textbf{AMB-G035} (Psychology PC Suite).
The schedule for the sessions is as follows:

\includegraphics{img/01-schedule.PNG}

\section{Do I need to bring a laptop to the class?}\label{do-i-need-to-bring-a-laptop-to-the-class}

If you have a laptop that you work on, please bring it.
That way, we can get R and RStudio installed onto your laptop, and you'll be able to run R outside of the classroom.

If you work with a desktop, don't worry.
The lab space will have computers that you can sign in and work on and use R.

\section{Office hours and why they are important for everyone (R Support - Ryan Donovan).}\label{office-hours-and-why-they-are-important-for-everyone-r-support---ryan-donovan.}

Programming concepts can take a while to sink in and it is naturally to need additional help.\\
But in my experience, students often worry about asking for help, often from fears of being judged by their instructor.
This fear is exacerbated in courses involving mathematics and programming, as students are quick to label themselves as ``\emph{no good}'' at these subjects.

This is a completely unwarranted belief.
My job is to teach you R.
Consequently, if you are reading the material or listening in class, and it's not sinking in at all, then that is \textbf{\emph{my fault, not yours.}} If this is happening, then it is important that this feedback is being relayed.
The most valuable teaching hours I've had are while talking with a student who is struggling to understand the material, because it forces me to see the errors in how I am explaining that material and adjust. That way, I learn better ways to explain a particular concept and the student comes with away with a greater understanding of said concept.
We all win.

So pretty please, do not be a silent martyr and let me know if you are struggling with any of the R-based material in this course.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1041}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1479}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.7452}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Staff Member & Office Hours & Location \\
Ryan Donovan

ryan.donovan@universityofgalway.ie & Wednesdays, 2.30-3.30pm.

(In-person or online option).

Time does not suit?

Just get in touch, we can arrange a different time. & 2065A, which is on the top floor of the Psychology building. It is in the corridor right next to the elevator.

Teams Link: \href{https://teams.microsoft.com/l/meetup-join/19\%3ameeting_NDQ1YjRiNmQtNDQ4MC00NjgzLWIwYTQtNWI5OTg3ZmE1NWRj\%40thread.v2/0?context=\%7b\%22Tid\%22\%3a\%2213e3b186-c446-4aab-9c6d-9ab9bb76816c\%22\%2c\%22Oid\%22\%3a\%22c088ea08-9d92-460e-8972-64cd26bc4899\%22\%7d}{click here} \\
\end{longtable}

\chapter{\texorpdfstring{\textbf{Getting Started with R and RStudio}}{Getting Started with R and RStudio}}\label{rstudio}

This session introduces the programming language R and the RStudio application. Today, we will download both R and RStudio, set up our RStudio environment, and write and run our first piece of R Code. This will set us up for the rest of the course.

\section{What is R?}\label{what-is-r}

R is a statistical programming language that enables us to directly communicate with our computers and ask it perform tasks. Typically we rely on button-click applications (e.g.~SPSS, Excel, Word) to communicate with our computers on our behalf. These applications translate our button-click commands into a language that our computer can understand. Our computer then carries out those commands, returns the results to the application, which then translates those results back to us.

Applications like SPSS are convenient. They usually have a user-friendly interface that makes it easy to communicate with our computer. Consequently, this means one can become highly competent in a short amount of time with such applications.

However, these applications also limit what we can do. For example, base SPSS is functional when it comes to creating data visualizations, but it is difficult to make major changes to your graph (e.g., making it interactive). If we want to create such visualizations, we will likely need to use an alternative application. Similarly, we might also be financially limited in our ability to use such apps, as proprietary software like SPSS is not cheap (\href{https://www.ibm.com/products/spss-statistics/pricing}{it can cost between \$3830 - 25200 for a single licence depending on the version})!

In contrast, R is a free, open-source statistical programming language that enables us to conduct comprehensive statistical analysis and create highly elegant visualizations. By learning R, we can cut out the middleman.

\begin{figure}
\centering
\includegraphics{img/01-bbc.png}
\caption{\label{fig:unnamed-chunk-1}BBC graphs created in R.}
\end{figure}

But why R and not a different programming language? R was developed by statisticians for the purpose of conducting statistic analysis. In contrast, other popular programming languages (Python, JavaScript, C) were designed for different purposes. Consequently, R contains an extensive vocabulary that enables us to carry out sophisticated and precise statistical analysis. I have both used R and Python (often used in Data Science) to conduct statistical analysis, and I have found it significantly easier in R to run a wide range of statistical tests. Similarly, there is extensive support available online to enable you to run statistical analyses in R. This explains why R is typically used among statisticians, social scientists, data miners, and bioinformaticians. For these reasons, we will be using R in this course \footnote{There are always tradeoffs in selecting a language. Many programming concepts are easier to grasp in Python than in R. Similarly, there is a lot of resources available for conducting machine-learning analysis in Python.

  But if you are goal is conduct data cleaning, analysis, visualization, and reporting, then R is a excellent choice. The good thing is that once you achieve a certain level of competency in one programming language, you will find it significantly easier to pick up a following one.}.

\section{Create a Posit Cloud Account.}\label{create-a-posit-cloud-account.}

In the next section, I am going to show you how to download R and RStudio onto your laptop. But before we do that, I want you to set up a free account on Posit Cloud (formerly known as RStudio Cloud). Posit Cloud enables you to run R and RStudio online for free, with no need to install anything.

\textbf{\emph{If you are using the desktops in the lab,}} then please only use Posit Cloud in all of our R and RStudio classes. It is much easier to run R and RStudio on Posit Cloud than on the absolute tragic disaster of an operating system they use on the desktop Windows machines. Please, please, please do not use the RStudio version on the desktop computers in the lab, or else your R life will be brutal and painful.

\textbf{\emph{If you are using your own laptop,}} then use Posit Cloud as a backup option in case any technical issues pop up. During class, we might not be able to solve those issues quickly and efficiently (in a large classroom, one must always account for Murphy's Law). Rather than being hamstrung by technical difficulties, you can sign into Posit Cloud and keep following along with the session.

You might be wondering, why not just use Posit Cloud? The reason is that there are some restrictions to the free version of Posit Cloud, namely that you can only use 25 hours per month and are limited in the amount of data you can use during that time. It's highly unlikely that we will hit those restrictions in the next 10 weeks, but if you primarily use your laptop and Posit Cloud secondarily, then we do not have to worry about that.

For those of you on the desktop computers, if you do hit the max limit, then get in touch with Ryan (email: ryan.donovan@universityofgalway.ie). The simplest solution is just to create a second Posit Cloud account.

\subsection{Instructions for Creating a Posit Cloud Account}\label{instructions-for-creating-a-posit-cloud-account}

To create a Posit Cloud account, please follow the following instructions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \href{https://login.posit.cloud/register?redirect=\%2Foauth\%2Fauthorize\%3Fredirect_uri\%3Dhttps\%253A\%252F\%252Fposit.cloud\%252Flogin\%26client_id\%3Dposit-cloud\%26response_type\%3Dcode\%26show_auth\%3D0}{Go to their sign up page website} and enter your details to create an account or Sign up with Google.

  \includegraphics{img/01-posit-sign-up.png}
\item
  Once you have created an account and are in Posit Cloud, click ``New Project'' From the drop-down menu click ``New RStudio Project''. This should take a few seconds to set up (or ``deploy'')
\end{enumerate}

\includegraphics{img/01-posit-newproject.png}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Once it is deployed, name your project at the top as \textbf{\emph{rintro}}
\end{enumerate}

\includegraphics{img/01-posit-rintro.png}

Don't worry about what anything on the screen means for now. We'll come back to that in the section \textbf{Creating an RProject (2.5).}

\section{Downloading R on to your Computer (personal laptop or desktops only)}\label{downloading-r-on-to-your-computer-personal-laptop-or-desktops-only}

If you are using your own personal laptop or desktop (if at home), then please follow the following instructions to download R on either Windows or Mac.

\textbf{\emph{If you are using the Desktops in the lab, do not follow these instructions, as we will be using Posit Cloud}}

\subsection{Downloading R on Windows}\label{downloading-r-on-windows}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Go to the website: \url{https://cran.r-project.org/}
\item
  Under the heading \emph{Download and Install R,} click \emph{Download R for Windows}
\end{enumerate}

\includegraphics{img/01-cran.png}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  Click the hyperlink \textbf{\emph{base}} or \textbf{\emph{install R for the first Time}}
\item
  Click Download R-4.4.2 for Windows (depending on the date you access this, the version of R might have been been updated. That's okay, you can download the newer version). Let the file download.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{img/01-base.png}
\caption{\label{fig:unnamed-chunk-6}The R programming language is occasionally updated, so the specific version of R that you see might be different than mine. But that's okay!}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Once the file has been downloaded, open it and click ``Yes'' if you are asked to allow this app to make changes to your device. Choose English as your setup language. The file name should be something like ``R-4.4.2.-win'' (numbers will differ depending on the version downloaded).
\item
  Agree to the terms and conditions and select a place to install R. The default option is fine.
\end{enumerate}

\subsection{Downloading R on Mac}\label{downloading-r-on-mac}

The instructions are largely the same for Mac.

\begin{itemize}
\item
  Go to the website: \url{https://cran.r-project.org/}
\item
  Click Download R for (Mac) OS X.
\end{itemize}

\includegraphics{img/01-rstudiodownload-mac.png}

\begin{itemize}
\tightlist
\item
  Check the \textbf{Latest release} section for the appropriate version and follow the directions for download. If you are unsure, please ask me.
\end{itemize}

\includegraphics{img/01-rversion-mac.png}

\begin{itemize}
\tightlist
\item
  Once the file download is complete, click to open the installer. Click \textbf{Continue} and proceed through the installer. I recommend going with all default options.
\end{itemize}

\begin{figure}
\centering
\includegraphics{img/01-mac_installer.png}
\caption{\label{fig:unnamed-chunk-9}Depending on your version of Mac OS, this might look slightly different. But you should still be able to install it.}
\end{figure}

\begin{itemize}
\tightlist
\item
  Once the R installer has finished, click \textbf{Close.}
\end{itemize}

\includegraphics{img/01-install_finish_mac.png}

\section{Install and Open RStudio}\label{install-and-open-rstudio}

Once R is installed, we will install RStudio. \textbf{\emph{Again, if you are using the desktops in the lab, you do not need to install RStudio---just make sure you have followed the Posit Cloud instructions.}}

RStudio is a user-friendly front-end program for R, enhancing your R coding experience without sacrificing any capabilities. RStudio allows us to write and save R code, create plots, manage files, and perform other useful tasks. Think of RStudio as similar to Microsoft Word compared to a basic text editor; while you can write a paper in a text editor, it's much quicker and more efficient in Word.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{NB:} Make sure that R is installed \textbf{\emph{before}} trying to install RStudio.
\item
  Go to the RStudio website: \url{https://posit.co/download/rstudio-desktop/.}
\item
  The website should automatically detect your operating system. Click the \textbf{\emph{Download RStudio Desktop}} button.
\end{enumerate}

\includegraphics{img/01-rstudiodownload.png}

Once the file is downloaded, open it and allow it to make changes to your device. Follow the instructions to install the program. I recommend using all the default options during installation.

After downloading both R and RStudio, open RStudio on your computer. You do not have to open R separately, as RStudio will work with R if everything is set up correctly.

When you first open RStudio, you will see three panes or ``windows'' in RStudio: \textbf{Console} (left), \textbf{Environment} (top right), and \textbf{Files} (bottom right).

\includegraphics{img/rstudio_first.png}

\section{Creating an R Project}\label{creating-an-r-project}

***Note: If you are using PositCloud instructions from 2.2.1, you have already created a project on PositCloud. Only follow this section if you are using your own computer or laptop.

Our first step in RStudio is to create an \emph{R Project}. R Projects are environments that group together input files (e.g., data sets), analyses on those files (e.g., code), and any outputs (e.g., results or plots). Creating an R Project will set up a new directory (folder) on your computer. Whenever you open that project, you are telling R to work within that specific directory (in this context, ``directory'' is just a fancy word for a folder).

\textbf{\emph{Activity - Create an R Project (Personal Computer or Laptop)}}

Let's create an R Project that we will use during these sessions

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Click ``File'' in the top left-hand corner of RStudio → then click ``New Project.''
\item
  The ``New Project Wizard'' screen will pop up. Click ``New Directory'' → ``New Project.''
\item
  In the ``Create New Project'' screen, there are four options we are going to change:
\end{enumerate}

\textbf{Option 1}: The ``Directory name'' options sets the name of the project and associated folder.

\begin{itemize}
\item
  I \textbf{\emph{recommend}} that you set the same directory name as me - \textbf{\emph{rintro}}
\item
  You can actually set this directory name to whatever you want, I cannot stop you. \textbf{\emph{Just don't set it to ``R'',}} as this can create problems down the line.
\end{itemize}

\textbf{Option 2}: The ``Create project as sub-directory of'' option selects a place to store this project on your computer.

\begin{itemize}
\item
  You can save it anywhere you like (e.g., your Desktop). Just ensure it's in a place you can easily find and where it won't be moved later.
\item
  My recommendation is to create a folder called ``PS6183'' on your desktop and save your project inside this folder.
\item
  Regardless of where you save your project, make a note of the location on your computer and keep it handy (e.g., in a text file).
\end{itemize}

\textbf{Option 3}: The ``Use renv with this project'' option enables you to create a virtual environment for this project that will be separate to other R projects. Don't worry for now about what that means, it will be explained later on.

\begin{itemize}
\tightlist
\item
  Tick this option.
\end{itemize}

\textbf{Option 4:} The ``Open in new session'' just opens a new window on RStudio for this project.

\begin{itemize}
\tightlist
\item
  Tick this option.
\end{itemize}

\textbf{Note on Github Repository}: This will probably not appear on your RStudio project, but that's okay, you don't need it for this course.

You can see my example below. Once you're happy with your input for each option, click ``Create Project'' This will open up the project \textbf{\emph{rintro}}.

\begin{figure}
\centering
\includegraphics{img/01-newproject-ma.png}
\caption{\label{fig:unnamed-chunk-13}New Project Set Up}
\end{figure}

\section{Navigating RStudio}\label{navigating-rstudio}

In our new project, \textbf{\emph{rintro}}, we are going to open the ``Source'' pane, which we will often use for writing code and viewing datasets.

\subsection{Opening the Source Pane}\label{opening-the-source-pane}

There are a variety of ways to open the Source pane:

\begin{itemize}
\tightlist
\item
  \textbf{Button approach}: Click the ``File'' tab in the top-left corner → Click ``New File'' → Select ``R Script.''
\end{itemize}

\includegraphics{img/rstudio_create_file.png}

\begin{itemize}
\item
  \textbf{Button Shortcut}: Directly underneath the \emph{File} tab, there is an icon of a white sheet with a green addition symbol. You can click that too.
\item
  \textbf{Keyboard Shortcut:} Press ``Ctrl'' + ``Shift'' + ``N'' on Windows, or ``Cmd'' + ``Shift'' + ``N'' on Mac.
\end{itemize}

Now you should see your four panes: \textbf{Source}, \textbf{Console}, \textbf{Environment}, and \textbf{Files}.

\includegraphics{img/01-four-panes.png}

\subsubsection{The RStudio Workspace}\label{the-rstudio-workspace}

Let's briefly describe the purpose of each pane:

\begin{itemize}
\item
  \textbf{Source Pane}: Where you write R scripts. R scripts enable you to write, save, and run R code in a structured format. For instance, you might have an R script titled ``Descriptive,'' containing code for computing descriptive statistics on your dataset. Similarly, you might have another R script titled ``Regression'' for performing regression analyses.
\item
  \textbf{Console Pane}: Where you can write R code or enter commands into R. The console also displays various outputs from your R scripts. For example, if you create a script for running a t-test, the results will appear here. Any error or warning messages related to your code will also be highlighted in the console. In short, this is where R actually runs your code.
\item
  \textbf{Environment Pane}: Displays information about datasets and variables imported or created in R within a specific project. The ``History'' tab shows a history of R code executed during the project. This pane is helpful for reviewing your work or returning to a project after some time.
\item
  \textbf{Files Pane}: Includes project files (Files tab), outputs of plots you create (Plots tab), a list of downloaded packages (Packages tab), and help documentation about R functions (Help tab).
\end{itemize}

We will use all four panes extensively during these classes.

\subsection{Checking our Working Directory}\label{checking-our-working-directory}

Every time you open a project or file in RStudio, it's good practice to check the working directory. The working directory is the environment on your computer where R is currently operating.

Ideally, you want the working directory to match the location of your R project. This ensures that any files you import into RStudio or any files you export (datasets, results, graphs) can be easily found in your R project folder. Checking the working directory can help prevent many common R problems.

To check the working directory, type the following into the console pane:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{getwd}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "/Users/ryandonovan 1/Desktop/rintro"
\end{verbatim}

This will display the current working directory where R is operating. Your working directory will likely differ from mine, which is normal. Just confirm that it matches the location you specified when creating your project (\textbf{Option 2}).

\subsection{Setting up a new Working Directory}\label{set_wd}

In our R Project, we are going to create a folder for Week 1 of the workshop. Anything we create in R will then be saved into this folder.

\begin{itemize}
\tightlist
\item
  Click ``Session'' in the RStudio toolbar → Select ``Set Working Directory'' → Click ``Choose Directory.''
\end{itemize}

\includegraphics{img/01-wd.png}

\begin{itemize}
\tightlist
\item
  By default, you should be in your R Project (e.g., \textbf{\emph{rintro}}).
\end{itemize}

\begin{itemize}
\item
  Within this R Project, create a new folder and call it ``week1.''
\item
  Click ``week1'' and then click ``Open.''
\end{itemize}

\includegraphics{img/01-new_wd.png}

You should see something like the following in your console

\begin{verbatim}
> setwd("C:/Users/0131045s/Desktop/Programming/R/Workshops/rintro/week1")
\end{verbatim}

Check whether this location is where you want to store your files for this course. If it is, you're all set. If not, let me know during class.

\subsection{Changing some default settings}\label{changing-some-default-settings}

Like most applications, RStudio comes with default settings, some of which can be annoying if you use R frequently. One such setting restores your data and commands from your last session when you reopen RStudio. While this sounds helpful, it can cause issues if you're working on multiple projects or sharing code with others. Let's change this setting:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In the toolbar at the top of RStudio, click \textbf{Tools} → \textbf{Global Options}.
\item
  Under the \textbf{General} tab, look for the ``Save workspace to .RData on exit'' option. Change it to ``Never.'' Untick the box as well.
\end{enumerate}

\includegraphics{img/01-workspace-setting.PNG}

\section{Writing our first R Code}\label{writing-our-first-r-code}

Let's write our first line of R code in the console. The R console uses the prompt symbol \texttt{\textgreater{}} to indicate that it is ready for a new line of code.

Type in each of the following instructions (after the \texttt{\textgreater{}} prompt) and press Enter. Feel free to modify the second line of code to include your own name:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{"Hello World"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Hello World"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{"My name is Ryan and I am learning to code in R"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "My name is Ryan and I am learning to code in R"
\end{verbatim}

Congratulations, you've written your first piece of code!

Let's describe what is going on here. We used a function called print() to print the words ``Hello World'' and ``My name is Ryan, and I am learning to code in R'' in the console. Functions are equivalent to verbs in the English language---they describe actions. Here, R identifies the \texttt{print()} function, looks inside the parentheses to see what we want to print, and then displays the specified text. Pretty straightforward.

Functions are a core programming concept, and there is a lot more going on under the hood than I have described so far. We'll revist functions repeatedly and filling you in with more information. But in essence, functions are verbs that enable us to tell our computer what actions to perform.

\section{Console vs Source Script}\label{console-vs-source-script}

You might have noticed that I asked you to write code in the console rather than the source pane. Let's discuss the differences:

\begin{itemize}
\item
  \textbf{Console}: This is like having a live chat with R. You type commands, and R executes them immediately. The console is great for experimentation and quick feedback but not ideal for saving or organising your work.
\item
  \textbf{Source Script}: This is where you write and save your code in a structured format. Scripts allow you to keep a record of your work, organise it into sections, and rerun it later. Think of the source pane as a document for your final code.
\end{itemize}

From now on, we'll write most of our code in R scripts. If I want you to use the console, I'll let you know.

\section{Let's write some statistical code}\label{firstpieceofcode}

Now that we've talked a lot about R and RStudio, let's write some code that will:

\begin{itemize}
\item
  Take a dataset
\item
  Calculate descriptive statistics
\item
  Generate a graph
\item
  Save the results
\end{itemize}

Don't worry if you don't understand all the code provided below. Just follow along and type it yourself into the R script we opened earlier. If it's not open, click ``File'' → ``New File'' → ``R Script.'' Save the script as \textbf{``01-sleep-descriptives.''}

When you download R, it comes with several built-in functions (e.g., \texttt{print()}) and datasets. One of these datasets is called \textbf{\texttt{sleep}}, which we'll use here. To learn more about the \textbf{\texttt{sleep}} dataset, type \textbf{\texttt{?sleep}} into the console. You'll find more information in the ``Help'' tab in the Files pane.

First, let's take a look at the \textbf{\texttt{sleep}} dataset by writing the following code in your R script. To run scripts in R, highlight the code and click the ``Run'' button (with the green arrow) in the top right corner of the script pane.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(sleep) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    extra group ID
## 1    0.7     1  1
## 2   -1.6     1  2
## 3   -0.2     1  3
## 4   -1.2     1  4
## 5   -0.1     1  5
## 6    3.4     1  6
## 7    3.7     1  7
## 8    0.8     1  8
## 9    0.0     1  9
## 10   2.0     1 10
## 11   1.9     2  1
## 12   0.8     2  2
## 13   1.1     2  3
## 14   0.1     2  4
## 15  -0.1     2  5
## 16   4.4     2  6
## 17   5.5     2  7
## 18   1.6     2  8
## 19   4.6     2  9
## 20   3.4     2 10
\end{verbatim}

The \textbf{\texttt{print()}} function displays the \textbf{\texttt{sleep}} dataset in the console. There are other functions to explore datasets, such as \textbf{\texttt{head()}}, \textbf{\texttt{tail()}}, \textbf{\texttt{View()}}, and \textbf{\texttt{str()}}. Try these functions with the \textbf{\texttt{sleep}} dataset by typing them into the console to see their outputs.

From \textbf{\texttt{print(sleep)}}, we can see there are 20 observations (rows) with three variables (columns):

\begin{itemize}
\item
  \textbf{extra}: The extra hours of sleep participants had
\item
  \textbf{group}: The treatment group they were assigned to
\item
  \textbf{ID}: Their participant ID
\end{itemize}

\subsection{Calculating Descriptive Statistics}\label{calculating-descriptive-statistics}

Let's calculate some descriptive statistics using the \textbf{\texttt{summary()}} function. This function takes an object (e.g., a dataset) and summarizes its data. Write the following code in your script and press ``Run'':

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(sleep) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      extra        group        ID   
##  Min.   :-1.600   1:10   1      :2  
##  1st Qu.:-0.025   2:10   2      :2  
##  Median : 0.950          3      :2  
##  Mean   : 1.540          4      :2  
##  3rd Qu.: 3.400          5      :2  
##  Max.   : 5.500          6      :2  
##                          (Other):8
\end{verbatim}

The \textbf{\texttt{summary()}} function provides descriptive statistics for each variable. For instance, it shows the mean change in hours of sleep (+1.5) and that there were 10 participants in each group.

However, this isn't quite what we need. For instance, we don't need descriptives for participant ID, and we want the mean scores split by treatment group. To get this, we can use the \textbf{\texttt{aggregate()}} function, which splits data into subsets and computes summary statistics for each subset. Add this to your script and run it:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{aggregate}\NormalTok{(}\AttributeTok{data =}\NormalTok{ sleep, extra }\SpecialCharTok{\textasciitilde{}}\NormalTok{ group, }\AttributeTok{FUN =}\NormalTok{ mean)}


\CommentTok{\#Here is what the code means}


\CommentTok{\# code: data = sleep meaning: Go to the sleep data set}

\CommentTok{\# code: extra \textasciitilde{} group meaning: Take the variable "extra" and split it into subsets based on the variable "group"}

\CommentTok{\# code: FUN = mean meaning: Apply the mean() function (FUN) on each subset }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   group extra
## 1     1  0.75
## 2     2  2.33
\end{verbatim}

Running this code shows the mean extra sleep for each treatment group. Participants in \textbf{group 2} slept an extra 2.33 hours on average, while participants in \textbf{group 1} slept only 0.75 hours more. It seems treatment 2 is more effective.

\subsection{Creating a Visualisation}\label{creating-a-visualisation}

It's always a good step to create visualisations with your data to get a better picture of what is going on. Let's visualise our data with the \texttt{plot()} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(sleep}\SpecialCharTok{$}\NormalTok{group, sleep}\SpecialCharTok{$}\NormalTok{extra)}
\end{Highlighting}
\end{Shaded}

\includegraphics{rintro_demo_files/figure-latex/unnamed-chunk-24-1.pdf}

The \textbf{\texttt{plot()}} function automatically determines the most appropriate plot---in this case, a boxplot. While this plot is functional, we can make it more informative by adding a title and labels for the axes:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#xlab = creates a label for the x{-}axis  }

\CommentTok{\#ylab = creates a title for the y{-}axis  }

\CommentTok{\#main = creates a title for the plot  }



\FunctionTok{plot}\NormalTok{(sleep}\SpecialCharTok{$}\NormalTok{group, sleep}\SpecialCharTok{$}\NormalTok{extra, }\AttributeTok{xlab =} \StringTok{"Treatment"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Hours of Sleep"}\NormalTok{, }\AttributeTok{main =} \StringTok{"Effect of Treament on Sleep Duration"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{rintro_demo_files/figure-latex/unnamed-chunk-25-1.pdf}
\caption{\label{fig:unnamed-chunk-25}Generic Boxplot with appropriate labelling}
\end{figure}

This plot is more descriptive and also suggests a difference between the two groups. But is this difference meaningful? Later in the course, we'll learn how to evaluate whether differences like these are statistically significant using inferential statistical tests.

\subsection{Saving the Plot}\label{saving-the-plot}

Now, let's take this plot and save it to a PDF so that we can share our results with others. The standard way of doing this in R is a bit cumbersome. We have to tell R that we are about to create a plot that we want to make into a PDF. Then we have to generate the plot. Then we have to tell R we are done with creating the PDF. We'll learn a much simpler way to do this in future weeks, but this will do for now.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pdf}\NormalTok{(}\AttributeTok{file =} \StringTok{"myplot.pdf"}\NormalTok{) }\CommentTok{\#Tells R that we will create a pdf file called "my\_plot" in our working directory}

\FunctionTok{plot}\NormalTok{(sleep}\SpecialCharTok{$}\NormalTok{group, sleep}\SpecialCharTok{$}\NormalTok{extra, }\AttributeTok{xlab =} \StringTok{"Treatment"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Hours of Sleep"}\NormalTok{, }\AttributeTok{main =} \StringTok{"Effect of Treament on Sleep Duration"}\NormalTok{)  }\CommentTok{\#this will save the plot to our pdf}


\FunctionTok{dev.off}\NormalTok{() }\CommentTok{\#this tells R that we are done with adding stuff to our PDF}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## pdf 
##   2
\end{verbatim}

Go to the files pane, and open up the pdf ``myplot.pdf''. It should be in your working directory. Open up the PDF and have a look at your graph\footnote{This is a fairly generic type of graph offered by base R. During the course we will looking at ways we can create ``sexier'' and more APA friendly type of graphs. But for one line of code, it's not bad!}.

\subsection{Comments}\label{comments}

You might have noticed that I wrote several lines of text with a \textbf{\texttt{\#}} before them. These are known as comments. Comments are pieces of text that R ignores---they are not executed as part of the code. They are fundamental to writing clear and understandable code.

We create comments using the \textbf{\texttt{\#}} symbol. This tells R to ignore everything that comes \textbf{after} the \texttt{\#} on the same line.

Comments serve a variety of purposes:

\begin{figure}
\centering
\includegraphics{img/03-comments.png}
\caption{\label{fig:unnamed-chunk-27}Four Examples of Comments Use}
\end{figure}

In the above figure, you'll see four different types of comments.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Provide an Introduction}: It can be really useful here to provide clear information on what this script is trying to do, what data it is working on (the sleep dataset), and who wrote or developed this script. This makes it significantly easier for anyone who might be reviewing your work or trying to apply your code to their own work to understand what is going on.
\item
  \textbf{Structure Your Script}: The second type of comment structures the format of the script by providing headings or steps. Again, this just makes it easier to understand what is going on.
\item
  \textbf{Disable Code Temporarily}: The third type of comment is placed before the summary. This means that the code \textbf{\texttt{summary(sleep)}} will not be executed in R. Why would we do this? If we wanted to temporarily disable a piece of code but not delete it, because we think might be useful later. This is useful if you want to skip certain steps or keep old code for reference.
\item
  \textbf{Explain Specific Lines of Code}: The fourth type of comment provides some context or information on what a specific line of code is doing, namely, what the \textbf{\texttt{aggregate()}} function does. Again, this is really useful, particularly if you are using functions that are not well-known.
\end{enumerate}

\subsection{Why Comments Are Important}\label{why-comments-are-important}

Writing comments is like leaving notes for your future self (or for others working with your code). Imagine this scenario: you spend weeks creating a detailed R script to clean a messy dataset and run complex analyses. Months later, a reviewer or your supervisor asks for changes. When you reopen your script, you realise you've forgotten what each piece of code does! Without comments, you may spend hours trying to understand your own work.

By including comments, you save time and frustration. Additionally, comments help you solidify your understanding by requiring you to explain your code as you write it.

\subsection{Best Practices for Comments}\label{best-practices-for-comments}

\begin{itemize}
\item
  Comment frequently: It's better to over-comment than to leave yourself guessing later.
\item
  Keep comments concise but clear: Avoid overly verbose comments that are harder to read.
\item
  Update comments if you change your code: Outdated comments can be misleading.
\item
  Use comments to break your script into logical sections.
\end{itemize}

\section{Summary}\label{summary}

There we have it! That completes our first session with R and RStudio. Today was more about getting to grips with the software R and RStudio, but we still got our first pieces of code written. Hopefully, it's given you a tiny glimpse into what R can do.

In the next two sessions, we will learn basic programming concepts that will help you use R effectively, learn how to import data in R, and learn how to run descriptive statistics.

\section{Glossary}\label{glossary}

This glossary defines key terms introduced in Chapter 2.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3056}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6944}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Comment & Text in an R script that is ignored by R. Comments are preceded by the \texttt{\#} symbol and are used to add explanations, headings, or disable code temporarily. \\
Console & The interactive interface in RStudio where you can type and execute R commands and see their immediate output. \\
Environment Pane & The pane in RStudio that displays information about data sets, variables, and the history of R commands used in the current R session. \\
Files Pane & The pane in RStudio that displays the files and folders in your current working directory, as well as other useful tabs like Plots, Packages, and Help. \\
Function & A fundamental programming concept in R, representing a reusable block of code that performs a specific task. Functions are like verbs in English; they describe actions. \\
R & A programming language and environment for statistical analysis and data visualization. \\
R Project & An environment created in RStudio that groups together input files, code, and outputs. It helps organize and manage your work in a specific directory. \\
RStudio & An integrated development environment (IDE) for R, providing a user-friendly interface and tools for coding, data analysis, and visualization. \\
Script & A file containing a sequence of R commands that can be saved, executed, and reused. \\
Source Pane & The pane in RStudio where you can write and edit R scripts. \\
Term & Definition \\
Working Directory & The directory or folder on your computer where R is currently operating. It is important for managing file paths and organizing project files. \\
\end{longtable}

\chapter{\texorpdfstring{\textbf{Programming Fundamentals in R (Part I)}}{Programming Fundamentals in R (Part I)}}\label{programming1}

In this session, we are going to introduce fundamental programming concepts in R. In particular, we will learn important information about the syntax and rules of R, best practices on creating variables, the different ways that R stores, handles, and structures data, and how we can create and access that data.

By the end of this session, you should be capable of the following:

\begin{itemize}
\tightlist
\item
  Running and troubleshooting commands in the R console.
\item
  Understanding different data types and when to use them.
\item
  Creating and using variables, and understanding best practices in naming variables.
\item
  Grasping key data structures and how to construct them.
\end{itemize}

\section{How to read this chapter}\label{how-to-read-this-chapter}

If you are reading this chapter. I recommend that you type out every piece of code that I show on the screen, even the code with errors. The reason for this is that it will increase your comfortably with using R and RStudio and writing code. You can then test your understanding in the activities.

\section{Activities}\label{activities}

There are several activities associated with this chapter. \href{https://ryandonovan.quarto.pub/week-2---activities/}{You can find them by clicking this link.}

\section{Using the Console}\label{using-the-console}

In the previous chapter, I made a distinction between the script and the console. I said that the script was an environment where we would write and run polished code, and the R console is an environment for writing and running ``dirty'' quick code to test ideas, or code that we would run once.

That distinction is kinda true, but it's not completely true. In reality, when we create a script we are preparing \textbf{\emph{commands}} for R to \textbf{\emph{execute}} in the console. In this sense, the R script is equivalent to a waiter. We tell the waiter (script) what we want to order, and then the waiter hands that order to the chef (console).

It's important to know how to work the R console, even if we mostly use scripts in these workshops. We don't want the chef to spit on our food.

\subsection{Typing Commands in the Console}\label{typing-commands-in-the-console}

We can type commands in the console to get R to perform calculations. Just a note, if you are typing these commands into the console, there is no need to type the \texttt{\textgreater{}} operator; it simply indicates that R is ready to execute a new command, which can be omitted for clarity.\footnote{Including the ``\textgreater{}'' is a pain when formatting this book, so I won't include ``\textgreater{}'' in examples of code from this point forward.}

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}} \DecValTok{10} \SpecialCharTok{+} \DecValTok{20}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{30}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}} \DecValTok{20} \SpecialCharTok{/} \DecValTok{10}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{2}
\end{Highlighting}
\end{Shaded}

R follows the BEMDAS convention when performing calculations (\href{https://www.tes.com/en-ie/teaching-resource/bidmas-bodmas-bedmas-bimdas-pemdas-permdas-11154272\#:~:text=\%E2\%80\%A2\%20BIMDAS\%20\%2D\%20Brackets\%2C\%20Indices\%2C,Multiplication\%2C\%20Division\%2C\%20Addition\%2C\%20Subtraction}{BEDMAS - Bracets, Exponents, Division, Multiplication, Addition, and Subtraction}). So if you are using R for this purpose, just be mindful of this if the result looks different from what you expected.

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}}\NormalTok{ (}\DecValTok{20} \SpecialCharTok{+} \DecValTok{10} \SpecialCharTok{/} \DecValTok{10}\NormalTok{) }\SpecialCharTok{*} \DecValTok{4} 

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{84}

\SpecialCharTok{\textgreater{}}\NormalTok{ ((}\DecValTok{20} \SpecialCharTok{+} \DecValTok{10}\NormalTok{) }\SpecialCharTok{/} \DecValTok{10}\NormalTok{) }\SpecialCharTok{*} \DecValTok{4}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{12}
\end{Highlighting}
\end{Shaded}

You may have noticed that the output after each of line of code has \textbf{\texttt{{[}1{]}}} before the actual result. What does this mean?

This is how R labels and organises its response. Think of it as having a conversation with R, where every question you ask gets an answer. The square brackets with a number, like \textbf{\texttt{{[}1{]}}}, serve as labels on each response, indicating which answer corresponds to which question. This is R \textbf{\emph{indexing}} its answer.

In all the examples above, we asked R questions that have only 1 answer, which is why the output is always \textbf{\texttt{{[}1{]}}}. Look what happens when I ask R to print out multiple answers.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(sleep}\SpecialCharTok{$}\NormalTok{extra) }\CommentTok{\#this will print out the extra sleep column in the sleep dataset we used last week}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  0.7 -1.6 -0.2 -1.2 -0.1  3.4  3.7  0.8  0.0  2.0  1.9  0.8  1.1  0.1 -0.1
## [16]  4.4  5.5  1.6  4.6  3.4
\end{verbatim}

Here R tells us that the first answer (i.e., value) corresponds to \texttt{0.1}. The next label is \texttt{{[}16{]}}. which tells us that the 16th answer corresponds to 4.4. If you run this code in your console, you might actually see a different number than \texttt{{[}16{]}} depending on wide your console is on your device.

But why does it only show the \texttt{{[}1{]}} and \texttt{{[}16{]}}th index? This is because R only prints out the index when a new row of data is needed in the console. If there were indexes for every single answer, it would clutter the console with unnecessary information. So R uses new rows as a method for deciding when to show us another index.

We'll delve deeper into indexing later in this session; it's a highly useful concept in R.

\subsection{Console Syntax (Aka ``I'm Ron Burgundy?'')}\label{console-syntax-aka-im-ron-burgundy}

\subsubsection{R Console and Typos}\label{r-console-and-typos}

One of the most important things you need to know when you are programming, is that you need to type \emph{exactly} what you want R to do. If you make a mistake (e.g., a typo), R won't attempt to decipher your intention. For instance, consider the following code:

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}} \DecValTok{10} \OtherTok{=} \DecValTok{20}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in 10 = 20: invalid (do_set) left-hand side to assignment
\end{verbatim}

R interprets this as you claiming that 10 equals 20, which is not true. Consequently, R panics and refuses to execute your command. Now any person looking at your code would guess that since \texttt{+} and \texttt{=} are on the same key on our keyboards, you probably meant to type \texttt{10\ +\ 20}. But that's because we have a theory of mind, whereas programming languages do not.

So be exact with your code or else be \href{https://www.youtube.com/watch?v=X3zfP14pLxc}{Ron Burgundy?}.

On the grand scheme of mistakes though, this type of mistake is relatively harmless because R will tell us immediately that something is wrong and stop us from doing anything.

However, there are silent types of mistakes that are more challenging to resolve. Imagine you typed \texttt{-} instead of \texttt{+}.

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}} \DecValTok{10} \SpecialCharTok{{-}} \DecValTok{20}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}}\DecValTok{10}
\end{Highlighting}
\end{Shaded}

In this scenario, R runs the code and produces the output. This is because the code still makes sense; it is perfectly legitimate to subtract 20 away from 10. R doesn't know you actually meant to add \texttt{10} to \texttt{20}. All it can see is three objects \texttt{10}, \texttt{-}, and \texttt{20} in a logical order, so it executes the command. In this relationship, you're the one in charge.

In short calculations like this, it is clear what you have typed wrong. However, if you have a long block of connected code with a typo like this, the result can significantly differ from what you intended, and it might be hard to spot.

The primary way to check for these errors is to always review the output of your code. If it looks significantly different from what you expected, then this silent error may be the cause.

I am not highlighting these issues to scare you, it's just important to know that big problems (R code not running or inaccurate results) can often be easily fixed by tiny changes.

\subsubsection{R Console and Incomplete Commands}\label{r-console-and-incomplete-commands}

I have been talking a lot of smack about the console, but there are rare times it will be a good Samaritan.

For example, if R thinks you haven't finished a command it will print out \texttt{+} to allow you to finish it.

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}}\NormalTok{ (}\DecValTok{20} \SpecialCharTok{+} \DecValTok{10}
 
\SpecialCharTok{+} 
\end{Highlighting}
\end{Shaded}

In this case, you just need to type finish the \texttt{)} next to the \texttt{+} symbol.

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}}\NormalTok{ (}\DecValTok{20} \SpecialCharTok{+} \DecValTok{10}
 
\SpecialCharTok{+}\NormalTok{ )}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{30}
\end{Highlighting}
\end{Shaded}

So when you see ``+'' in the console, this is R telling you that something is missing. R won't let you enter a new command until you have finished with it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{20} \SpecialCharTok{+} \DecValTok{10}

\SpecialCharTok{+} \CommentTok{\#if I press enter, it will keep appearing until I finish the code or press Esc}
\SpecialCharTok{+}
\SpecialCharTok{+}
\SpecialCharTok{+}
\SpecialCharTok{+}\NormalTok{ )}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{30}
\end{Highlighting}
\end{Shaded}

If nothing is missing, then this indicates that your code might not be correctly formatted. To break out of the endless loops of ``+'', press the \textbf{\emph{Esc}} key on your keyboard.

\section{Data Types}\label{data-types}

Our overarching goal for this course is to enable you to import your data into R, prepare it for analysis, conduct descriptive and statistical analysis, and create nice data visualisations.

Each of these steps becomes significantly easier to perform if we understand \textbf{\emph{What is data and how is it stored in R?}}

Data comes in various forms, such numeric (integers and decimal values) or alphabetical (characters or lines of text). R has developed a system for categorising this range of data into different data types.

\section{Basic Data types in R}\label{basic-data-types-in-r}

R has 4 basic data types that are used 99\% of the time. We will focus on these following data types:

\subsection{Character}\label{character}

A character is anything enclosed within quotation marks. It is often referred to as a \emph{string}. Strings can contain any text within single or double quotation marks.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#we can use the class() function to check the data type of an object in R}

\FunctionTok{class}\NormalTok{(}\StringTok{"a"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\StringTok{"cat"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

Numbers enclosed in quotation marks are also recognised as character types in R.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\StringTok{"3.14"}\NormalTok{) }\CommentTok{\#recognized as a character}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\StringTok{"2"}\NormalTok{) }\CommentTok{\#recognized as a character}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\FloatTok{2.13}\NormalTok{) }\CommentTok{\#not recognised as a character}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

\subsection{Numeric (or Double)}\label{numeric-or-double}

In R, the numeric data type represents all real numbers, with or without decimal value, such as:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\DecValTok{33}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\FloatTok{33.33}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "numeric"
\end{verbatim}

\subsection{Integer}\label{integer}

An integer is any real whole number without decimal points. We tell R to specify something as an integer by adding a capital ``L'' at the end.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\DecValTok{33}\DataTypeTok{L}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "integer"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\DataTypeTok{L}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "integer"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\DecValTok{0}\DataTypeTok{L}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "integer"
\end{verbatim}

You might wonder why R has a separate data type for integers when numeric/double data types can also represent integers.

The very technical and boring answer is that integers consume less memory in your computer compared to the numeric or double data types. `\texttt{33\ contains\ less\ information\ than\ 33.00}`. So, when dealing with very large datasets (in the millions) consisting exclusively of integers, using the integer data type can save substantial storage space.

It is unlikely that you will need to use integers over numeric/doubles for your own research, but its good to be aware of just in case.

\subsection{Logical (otherwise know as Boolean)}\label{logical-otherwise-know-as-boolean}

The Logical data type has two possible values: \textbf{\texttt{TRUE}} or \textbf{\texttt{FALSE}}. In programming, we frequently need to make decisions based on whether specific conditions are true or false. For instance, did a student pass the exam? Is a p-value below 0.05\footnote{If you do not know what a p-value is, do not worry. We will introduce this concept later and discuss it extensively.}?

The Logical data type in R allows us to represent and work with these true or false values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "logical"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "logical"
\end{verbatim}

One important note is that it is case-sensitive, so typing any of the following will result in errors:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(True)   }\CommentTok{\# Error: object \textquotesingle{}True\textquotesingle{} not found}
\FunctionTok{class}\NormalTok{(False)  }\CommentTok{\# Error: object \textquotesingle{}False\textquotesingle{} not found}
\FunctionTok{class}\NormalTok{(true)   }\CommentTok{\# Error: object \textquotesingle{}true\textquotesingle{} not found}
\FunctionTok{class}\NormalTok{(false)  }\CommentTok{\# Error: object \textquotesingle{}false\textquotesingle{} not found}
\end{Highlighting}
\end{Shaded}

\subsection{Data Types - So What?}\label{data-types---so-what}

The distinction between data types in programming is crucial because some operations are only applicable to specific data types. For example, mathematical operations like addition, subtraction, multiplication, and division are only meaningful for numeric and integer data types.

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{11.00} \SpecialCharTok{+} \FloatTok{3.23} \CommentTok{\#will work}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\FloatTok{14.23}


\DecValTok{11} \SpecialCharTok{*} \DecValTok{10} \CommentTok{\#will work}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{120}

\StringTok{"11"} \SpecialCharTok{+} \DecValTok{3} \CommentTok{\# gives error}

\NormalTok{Error }\ControlFlowTok{in} \StringTok{"11"} \SpecialCharTok{+} \DecValTok{3} \SpecialCharTok{:}\NormalTok{ non}\SpecialCharTok{{-}}\NormalTok{numeric argument to binary operator}
\end{Highlighting}
\end{Shaded}

This is an important consideration when debugging errors in R. It's not uncommon to encounter datasets where a column that should be numeric is incorrectly saved as a character. This can be problematic if we need to perform statistical operations (e.g., calculating the mean) on that column. Luckily, there are ways to convert data types from one type to another.

\subsection{Data Type Transformation}\label{data-type-transformation}

Following on from our previous example, we can convert a data type into numeric using the \textbf{\texttt{as.numeric()}} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{as.numeric}\NormalTok{(}\StringTok{"22"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 22
\end{verbatim}

The following functions enable you to convert one data type to another:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{as.character}\NormalTok{()  }\CommentTok{\# Converts to character}
\FunctionTok{as.integer}\NormalTok{()    }\CommentTok{\# Converts to integer}
\FunctionTok{as.logical}\NormalTok{()    }\CommentTok{\# Converts to logical}
\end{Highlighting}
\end{Shaded}

\section{Variables}\label{variables}

Until now, the code we have used has been disposable; once you type it, you can only view its output. However, programming languages allow us to store information in objects called \textbf{\emph{variables.}}

Variables are labels for pieces of information. Instead of running the same code to produce information each time, we can assign it to a variable. Let's say I have a character object that contains my name. I can save that character object to a variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \StringTok{"Ryan"}
\end{Highlighting}
\end{Shaded}

To create a variable, we specify the variable's name (in this case, \textbf{\texttt{name}}), use the assignment operator (\textbf{\texttt{\textless{}-}}) to inform R that we're storing information in \textbf{\texttt{name}}, and finally, provide the data that we will be stored in that variable (in this case, the string ``Ryan''). Once we execute this code, every time R encounters the variable \textbf{\texttt{name}}, it will substitute it with ``Ryan.''

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(name)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Ryan"
\end{verbatim}

Some of you might have seen my email and thought, \emph{``Wait a minute, isn't your first name Brendan? You fraud!''} Before you grab your pitchforks, yes, you are technically correct. Fortunately, we can reassign our variable labels to new information.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \StringTok{"Brendan"} \CommentTok{\#please do not call me this}

\FunctionTok{print}\NormalTok{(name)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Brendan"
\end{verbatim}

We can use variables to store information for each data type.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{age }\OtherTok{\textless{}{-}} \DecValTok{30}\DataTypeTok{L}

\NormalTok{height }\OtherTok{\textless{}{-}} \DecValTok{175} \CommentTok{\#centimetre }

\NormalTok{live\_in\_hot\_country }\OtherTok{\textless{}{-}} \ConstantTok{FALSE}

\FunctionTok{print}\NormalTok{(age)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 30
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(height)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 175
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(live\_in\_hot\_country)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{paste}\NormalTok{(}\StringTok{"My name is"}\NormalTok{, name, }\StringTok{"I am"}\NormalTok{, age, }\StringTok{"years old and I am"}\NormalTok{, height, }\StringTok{"cm tall. It is"}\NormalTok{, live\_in\_hot\_country, }\StringTok{"that I was born in a hot country"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "My name is Brendan I am 30 years old and I am 175 cm tall. It is FALSE that I was born in a hot country"
\end{verbatim}

We can also use variables to perform calculations with their information. Suppose I have several variables representing my scores on five items measuring Extraversion (labeled \textbf{\texttt{extra1}} to \textbf{\texttt{extra5}}). I can use these variable names to calculate my total Extraversion score.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{extra1 }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{extra2 }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{extra3 }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{extra4 }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{extra5 }\OtherTok{\textless{}{-}} \DecValTok{3}

\NormalTok{total\_extra }\OtherTok{\textless{}{-}}\NormalTok{ extra1 }\SpecialCharTok{+}\NormalTok{ extra2 }\SpecialCharTok{+}\NormalTok{ extra3 }\SpecialCharTok{+}\NormalTok{ extra4 }\SpecialCharTok{+}\NormalTok{ extra5}

\FunctionTok{print}\NormalTok{(total\_extra)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean\_extra }\OtherTok{\textless{}{-}}\NormalTok{  total\_extra}\SpecialCharTok{/}\DecValTok{5}

\FunctionTok{print}\NormalTok{(mean\_extra)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.4
\end{verbatim}

Variables are a powerful tool in programming, enabling us to create code that works across various situations.

\subsection{What's in a name? (Conventions for Naming Variables)}\label{whats-in-a-name-conventions-for-naming-variables}

There are strict and recommended rules for naming variables that you should be aware of.

\textbf{Strict Rules (Must follow to create a variable in R)}

\begin{itemize}
\item
  Variable names can only contain uppercase alphabetic characters (A-Z), lowercase (a-z), numeric characters (0-9), periods \texttt{(.)}, and underscores \texttt{(\_)}.
\item
  Variable names must begin with a letter or a period (e.g., \textbf{\texttt{1st\_name}} or \textbf{\texttt{\_1stname}} is incorrect, while \textbf{\texttt{first\_name}} or \textbf{\texttt{.firstname}} is correct).
\item
  Avoid using spaces in variable names (\textbf{\texttt{my\ name}} is not allowed; use either \textbf{\texttt{my\_name}} or \textbf{\texttt{my.name}}).
\item
  Variable names are case-sensitive (\textbf{\texttt{my\_name}} is not the same as \textbf{\texttt{My\_name}}).
\item
  Variable names cannot include special words reserved by R (e.g., if, else, repeat, while, function, for, in, TRUE, FALSE). While you don't need to memorize this list, it's helpful to know if an error involving your variable name arises. With experience, you'll develop an intuition for valid names.
\end{itemize}

\textbf{Recommended Rules (Best practices for clean and readable code):}

\begin{itemize}
\item
  Choose informative variable names that clearly describe the information they represent. Variable names should be self-explanatory, aiding in code comprehension. For example, use names like ``income,'' ``grades,'' or ``height'' instead of ambiguous names like ``money,'' ``performance,'' or ``cm.''
\item
  Opt for short variable names when possible. Concise names such as \textbf{\texttt{dob}} (date of birth) or \textbf{\texttt{iq}} (intelligence quotient) are better than lengthy alternatives like \textbf{\texttt{date\_of\_birth}} or \textbf{\texttt{intelligence\_quotient}}. Shorter names reduce the chances of typos and make the code more manageable.
\item
  However, prioritize clarity over brevity. A longer but descriptive variable name, like \textbf{\texttt{total\_exam\_marks}}, is preferable to a cryptic acronym like \textbf{\texttt{tem}}. A rule of thumb is that if an acronym would make sense to anyone seeing the data, then use it. Otherwise, you a more descriptive variable name.
\item
  Avoid starting variable names with a capital letter. While technically allowed, it's a standard convention in R to use lowercase letters for variable and function names. Starting a variable name with a capital letter may confuse other R users.
\item
  Choose a consistent naming style and stick to it. There are three common styles for handling variables with multiple words:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    \textbf{snake\_case}: Words are separated by underscores (e.g., \textbf{\texttt{my\_age}}, \textbf{\texttt{my\_name}}, \textbf{\texttt{my\_height}}). This is the preferred style for this course as it aligns with other programming languages.
  \item
    \textbf{dot.notation}: Words are separated by periods (e.g., \textbf{\texttt{my.age}}, \textbf{\texttt{my.name}}, \textbf{\texttt{my.height}}).
  \item
    \textbf{camelCase}: Every word, except the first, is capitalized (e.g., \textbf{\texttt{myAge}}, \textbf{\texttt{myName}}, \textbf{\texttt{myHeight}}).
  \end{enumerate}
\end{itemize}

For the purposes of this course, I recommend using \textbf{\texttt{snake\_case}} to maintain consistency with my code. Feel free to choose your preferred style outside of this course, but always maintain consistency.

\section{Data Structures}\label{data-structures}

So far, we have talked about the different types of data that we encounter in the world and how R classifies them. We have also discussed how we can store this type of data in variables for later use. However, in data analysis, we rarely work with individual variables. Typically, we work with large collections of variables that have a particular order. For example, datasets are organized by rows and columns.

Collections of variables like datasets are known as \textbf{data structures.} Data structures provide a framework for organising and grouping variables together. In R, there are several different types of data structures, with each structure having specified rules for how to create, change, or interact with them. For the final part of this session, we are going to introduce the two main data structures used in this course: \textbf{\texttt{vectors}} and \textbf{\texttt{data\ frames}}.

\subsection{Vectors}\label{vectors}

The most basic and important data structure in R is \textbf{\emph{vectors}}. You can think of vectors as a list of data in R that are of the same data type.

For example, I could create a character vector with names of people in the class:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_names }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Gerry"}\NormalTok{, }\StringTok{"Aoife"}\NormalTok{, }\StringTok{"Liam"}\NormalTok{, }\StringTok{"Eva"}\NormalTok{, }\StringTok{"Helena"}\NormalTok{, }\StringTok{"Ciara"}\NormalTok{, }\StringTok{"Niamh"}\NormalTok{, }\StringTok{"Owen"}\NormalTok{)}


\FunctionTok{print}\NormalTok{(rintro\_names)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Gerry"  "Aoife"  "Liam"   "Eva"    "Helena" "Ciara"  "Niamh"  "Owen"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.vector}\NormalTok{(rintro\_names) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

And I can create a numeric vector with their marks (which were randomly generated!)\footnote{I used the function \texttt{rnorm()} to generate these values. If you want to read more about this very handy function, type \texttt{?rnorm} into the console, or follow this \href{https://www.statology.org/r-runif-vs-rnorm/}{link}.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_marks }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{69}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{80}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{86}\NormalTok{, }\DecValTok{88}\NormalTok{, }\DecValTok{92}\NormalTok{, }\DecValTok{71}\NormalTok{)}

\FunctionTok{print}\NormalTok{(rintro\_marks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 69 65 80 77 86 88 92 71
\end{verbatim}

And I can create a logical vectors that describes whether or not they were satisfied with the course (again randomly generated!):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_satisfied }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{) }

\FunctionTok{print}\NormalTok{(rintro\_satisfied)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE
\end{verbatim}

Technically, we have been using vectors the entire class. Vectors can have as little as 1 piece of data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{instructor }\OtherTok{\textless{}{-}} \StringTok{"Ryan/Brendan"}

\FunctionTok{is.vector}\NormalTok{(instructor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

However, we can't include multiple data types in the same vector. Going back to our numeric marks vector, look what happens when we try to add in a character grade to it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_grades }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{69}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{80}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{86}\NormalTok{, }\DecValTok{88}\NormalTok{, }\StringTok{"A1"}\NormalTok{, }\DecValTok{71}\NormalTok{)}


\FunctionTok{print}\NormalTok{(rintro\_grades)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "69" "65" "80" "77" "86" "88" "A1" "71"
\end{verbatim}

So what happened here? Well, R has converted every element within the \texttt{rintro\_grades} vector into a character. The reason for this is that R sees that we are trying to create a vector, but sees that there are different data types (numeric and character) within that vector. Since a vector can only have elements with the same data type, it will try to convert each element to one data type. Since it is easier to convert numerics into character (all it has to do it put quotation marks around each number) then characters into a vector (how would R know what number to convert A1 into?), it converts every element in \texttt{r\_intro\_grades} into a character.

This is a strict rule in R. A vector can only be created if every single element (i.e., thing) inside that vector is of the same data type.

If we were to check the class of \texttt{rintro\_marks} and \texttt{rintro\_grades}, it will show us this conversion

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(rintro\_marks) }

\NormalTok{[}\DecValTok{1}\NormalTok{] }\StringTok{"numeric"}


\FunctionTok{class}\NormalTok{(rintro\_grades)}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\StringTok{"character"}
\end{Highlighting}
\end{Shaded}

Remember how I mentioned that you might download a dataset with a column that has numeric data but is actually recognized as characters in R? This is one scenario where that could happen. The person entering the data might have accidentally entered text into a cell within a data column. When R reads this column, it sees the text, and then R converts the entire column into characters.

\subsubsection{Working with Vectors}\label{working-with-vectors}

We can perform several types of operations on vectors to gain useful information about it.

\textbf{Numeric and Integer Vectors}

We can run functions on vectors. For example, we can run functions like \textbf{\texttt{mean()}}, \textbf{\texttt{median}}, or \textbf{\texttt{sd()}} to calculate descriptive statistics on numeric or integer-based vectors:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(rintro\_marks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 78.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{median}\NormalTok{(rintro\_marks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 78.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(rintro\_marks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9.724784
\end{verbatim}

A useful feature is that I can sort my numeric and integer vectors based on their scores:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sort}\NormalTok{(rintro\_marks) }\CommentTok{\#this will take the original vector and arrange from lowest to highest scores}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 65 69 71 77 80 86 88 92
\end{verbatim}

The \textbf{\texttt{sort()}} function by default arranges from lowest to highest, but we can also tell it to arrange from highest to lowest.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sort}\NormalTok{(rintro\_marks, }\AttributeTok{decreasing =} \ConstantTok{TRUE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 92 88 86 80 77 71 69 65
\end{verbatim}

\textbf{Character and Logical Vectors}

We are more limited when it comes to operators with character and logical vectors. But we can use functions like \texttt{summary()} to describe properties of character or logical vectors.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(rintro\_names)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Length     Class      Mode 
##         8 character character
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(rintro\_satisfied)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Mode   FALSE    TRUE 
## logical       4       4
\end{verbatim}

The \textbf{\texttt{summary()}} function tells me how many elements are in the character vector (there are six names), whereas it gives me a breakdown of results for the logical vector.

\subsubsection{Vector Indexing and Subsetting}\label{vector-indexing-and-subsetting}

A vector in R is like a list of items. To be more specific, vectors in R are actually \emph{ordered} lists of items. Each item in that list will have a position (known as its index). When you create that list (i.e.~vector), the order in which you input the items (elements) determines its position (index). So the first item is at index 1, the second at index 2, and so on. Think of it like numbering items in a shopping list:

\begin{figure}
\centering
\includegraphics{img/03-index_numeric.png}
\caption{\label{fig:unnamed-chunk-67}Indexing for Numeric Vector}
\end{figure}

\begin{figure}
\centering
\includegraphics{img/03-index-character.png}
\caption{\label{fig:unnamed-chunk-68}Indexing for Character Vector}
\end{figure}

\begin{figure}
\centering
\includegraphics{img/03-index-logical.png}
\caption{\label{fig:unnamed-chunk-69}Indexing for Logical Vector}
\end{figure}

This property in vectors means we are capable of extracting specific items from a vector based on their position. If I wanted to extract the first item in my list, I can do this by using \textbf{\texttt{{[}{]}}} brackets:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_names[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Gerry"
\end{verbatim}

Similarly, I could extract the 3rd element.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_marks[}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 80
\end{verbatim}

Or I could extract the last element.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_satisfied[}\DecValTok{8}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

This process is called subsetting. I am taking an original vector and taking a sub-portion of its original elements.

I can ask R even to subset several elements from my vector based on their position. Let's say I want to subset the 2nd, 4th, and 6th elements. I just need to use \textbf{\texttt{c()}} to tell R that I am subsetting several elements:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_names[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Aoife" "Eva"   "Owen"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_marks[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 65 77 71
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_satisfied[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  TRUE FALSE FALSE
\end{verbatim}

If the elements you are positioned right next to each other on a vector, you can use \textbf{\texttt{:}} as a shortcut:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_names[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{)] }\CommentTok{\#this will extract the elements in index 1, 2, 3, 4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Gerry" "Aoife" "Liam"  "Eva"
\end{verbatim}

It's important to know, however, that when you perform an operation on a vector or you subset it, it does not actually change the original vector. None of these following code will actually change the variable \textbf{\texttt{rintro\_marks}.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sort}\NormalTok{(rintro\_marks, }\AttributeTok{decreasing =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{91} \DecValTok{90} \DecValTok{89} \DecValTok{88} \DecValTok{87} \DecValTok{87}

\FunctionTok{print}\NormalTok{(rintro\_marks)}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{69} \DecValTok{65} \DecValTok{80} \DecValTok{77} \DecValTok{86} \DecValTok{88} \DecValTok{92} \DecValTok{71}

\NormalTok{rintro\_marks[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)]}

\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{87} \DecValTok{91} \DecValTok{87}

\FunctionTok{print}\NormalTok{(rintro\_marks)}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\DecValTok{69} \DecValTok{65} \DecValTok{80} \DecValTok{77} \DecValTok{86} \DecValTok{88} \DecValTok{92} \DecValTok{71}
\end{Highlighting}
\end{Shaded}

You can see that neither the \textbf{\texttt{sort()}} function nor subsetting changed the original vector. They just outputted a result to the R console. If I wanted to actually save their results, then I would need to assign them to a variable.

Here's how I would extract and save the top three exam marks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{marks\_sorted }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(rintro\_marks, }\AttributeTok{decreasing =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{marks\_top }\OtherTok{\textless{}{-}}\NormalTok{ marks\_sorted[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)]}

\FunctionTok{print}\NormalTok{(marks\_top)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 92 88 86
\end{verbatim}

\subsubsection{Vectors - making it a little less abstract.}\label{vectors---making-it-a-little-less-abstract.}

You might find the discussion of vectors, elements, and operations very abstract - I did when I was learning R. While the list analogy is helpful, it only works for so long before it becomes problematic, mainly because there's another data structure called \textbf{\texttt{lists}}. This confused me.

What helped me understand vectors was realising that a vector is simply a ``line of data.'' Imagine we're running a study and collecting data on participants' age. When we open the Excel file, there will be a column called ``age'' with all the ages of our participants. That column is like a vector in R, containing a single line of data, where every value must be of the same type. For example, a column of ages in Excel becomes this vector in R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{age }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{43}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{44}\NormalTok{,}\DecValTok{32}\NormalTok{, }\DecValTok{56}\NormalTok{, }\DecValTok{67}\NormalTok{, }\DecValTok{32}\NormalTok{, }\DecValTok{23}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{img/03-column-vector.png}

Similarly, rows are lines of data going horizontally. Imagine, I collect data from another participant (p11). I could represent the data from that individual participant like this in R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p11 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{175}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

So whenever you think of a vector, just remember that it refers to a line of data, like a column or a row.

\begin{figure}
\centering
\includegraphics{img/03-vectors-summarised.png}
\caption{\label{fig:unnamed-chunk-82}Vectors can visually conceptualised as a column or row of data.}
\end{figure}

What happens when we combine different vectors (columns and rows) together? We create a \textbf{\texttt{data\ frame}}.

\subsection{Data frames}\label{data-frames}

A data frame is a rectangular data structure that is composed of rows and columns. A data frame in R is like a spreadsheet in Excel or a table in a word document:

\begin{figure}
\centering
\includegraphics{img/03-dataframes_vectors.png}
\caption{\label{fig:unnamed-chunk-83}The relationship between data frames and vectors. The different colours in the data frame indicate they are composed of independent vectors}
\end{figure}

Data frames are an excellent way to store and manage data in R because they can store different types of data (e.g., character, numeric, integer) all within the same structure.

Let's create such a data frame using the \textbf{\texttt{data.frame()}} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{name =} \FunctionTok{c}\NormalTok{(}\StringTok{"Alice"}\NormalTok{, }\StringTok{"Bob"}\NormalTok{, }\StringTok{"Charlie"}\NormalTok{), }\CommentTok{\#a character vector}
  \AttributeTok{age =} \FunctionTok{c}\NormalTok{(}\DecValTok{25}\DataTypeTok{L}\NormalTok{, }\DecValTok{30}\DataTypeTok{L}\NormalTok{, }\DecValTok{22}\DataTypeTok{L}\NormalTok{), }\CommentTok{\#an integer vector}
  \AttributeTok{score =} \FunctionTok{c}\NormalTok{(}\FloatTok{95.65}\NormalTok{, }\FloatTok{88.12}\NormalTok{, }\FloatTok{75.33}\NormalTok{) }\CommentTok{\#a numeric vector}
\NormalTok{)}

\NormalTok{my\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      name age score
## 1   Alice  25 95.65
## 2     Bob  30 88.12
## 3 Charlie  22 75.33
\end{verbatim}

Take a moment and think about what is going on inside \texttt{data.frame}. We have three variables \texttt{name}, \texttt{age}, \texttt{score}. Each of these variables correspond to a different type of vector (character, integer, and numeric). Or in other words, each of these variables correspond to different lines of data. We use the \texttt{data.frame} function to combine these vectors together into a table.

\subsubsection{Selecting Data from a Data Frame}\label{selecting-data-from-a-data-frame}

Once you have created or imported a data frame, you will often need to access it and perform various tasks and analyses. Let's explore how to access data within a data frame effectively.

\paragraph{Selecting Columns}\label{selecting-columns}

Columns in a data frame represent different variables or attributes of your data. Often in data analysis, we want to select a specific column and then perform analyses on it. So how can we individually select columns? Well, in a data frame, every column has a name, similar to how each column in an Excel spreadsheet has a header. These column names enable you to access and manipulate specific columns or variables within your data frame.

We select columns based on their names via two methods:

The \textbf{\$} Notation: You can use a dollar sign (\$) followed by the column name to select \textbf{an individual column} in a data frame. For example, let's select the \textbf{\texttt{name}} column in the \textbf{\texttt{my\_df}} data frame:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df}\SpecialCharTok{$}\NormalTok{name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Alice"   "Bob"     "Charlie"
\end{verbatim}

\textbf{Square Brackets} \textbf{\texttt{{[}{]}}}: This is a similar approach to accessing elements from a vector. Inside the brackets, you can specify both the row and columns that you want to extract. The syntax for selecting rows and columns is: \textbf{\texttt{the\ dataframe{[}the\ rows\ we\ want,\ the\ columns\ we\ want{]}}}.

So if we wanted to access the ``age'' column of \textbf{\texttt{my\_df}}, we could run the following code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df[, }\StringTok{"age"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 25 30 22
\end{verbatim}

You will notice that we left the ``rows'' part empty in the square brackets. Leaving this empty tells R ``keep all the rows for this column.''

We can also use this approach to access multiple columns using the \textbf{\texttt{c()}} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"score"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   age score
## 1  25 95.65
## 2  30 88.12
## 3  22 75.33
\end{verbatim}

\paragraph{Selecting Rows}\label{selecting-rows}

Rows in a data frame represent individual observations or records. You can access rows using indexing, specifying the row number you want to retrieve, following the syntax: \textbf{\texttt{the\ dataframe{[}the\ rows\ we\ want,\ the\ columns\ we\ want{]}}}.

To get the first row of your data frame (\textbf{\texttt{my\_df}}), you can type the following:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df[}\DecValTok{1}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    name age score
## 1 Alice  25 95.65
\end{verbatim}

This time I left the columns part blank; this tells R ``please keep all the columns for each row.''

To access the third row:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df[}\DecValTok{3}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      name age score
## 3 Charlie  22 75.33
\end{verbatim}

If you want multiple rows, you can use the \textbf{\texttt{c()}} function to select multiple rows. Let's select the 1st and 3rd rows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{), ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      name age score
## 1   Alice  25 95.65
## 3 Charlie  22 75.33
\end{verbatim}

If you wanted to select a range of rows, you can use the : operator:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df[}\DecValTok{2}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       name age score
## 2      Bob  30 88.12
## 3  Charlie  22 75.33
## NA    <NA>  NA    NA
\end{verbatim}

These methods allow you to extract specific rows or subsets of rows from your data frame.

\paragraph{Selecting Rows and Columns}\label{selecting-rows-and-columns}

We can also select both rows and columns using \textbf{\texttt{{[}{]}}} and our syntax: \textbf{\texttt{the\ dataframe{[}the\ rows\ we\ want,\ the\ columns\ we\ want{]}}}.

For example, we could select the first and third rows for the \textbf{\texttt{Age}} and \textbf{\texttt{Score}} columns:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"score"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   age score
## 1  25 95.65
## 3  22 75.33
\end{verbatim}

Similar to when we indexed vectors, this won't change the underlying data frame. To do that, we would need to assign the selection to a variable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df2 }\OtherTok{\textless{}{-}}\NormalTok{ my\_df[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"score"}\NormalTok{)]}

\NormalTok{my\_df2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   age score
## 1  25 95.65
## 3  22 75.33
\end{verbatim}

\subsubsection{Adding Data to your Data Frame}\label{adding-data-to-your-data-frame}

\paragraph{Adding Columns}\label{adding-columns}

You may often need to add new information to your data frame. For example, we might be interested in investigating the effect of \textbf{\texttt{Gender}} on the \textbf{\texttt{Score}} variable. The syntax for creating a new data frame is very straightforward:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{existing\_df}\SpecialCharTok{$}\NormalTok{NewColumn }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(Value1, Value2, Value3)}
\end{Highlighting}
\end{Shaded}

Using this syntax, let's add a \textbf{\texttt{Gender}} column to our \textbf{\texttt{my\_df}} dataframe:.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df}\SpecialCharTok{$}\NormalTok{gender }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Female"}\NormalTok{, }\StringTok{"Non{-}binary"}\NormalTok{, }\StringTok{"Male"}\NormalTok{)}

\CommentTok{\#let\textquotesingle{}s see if we have successfully added a new column in}

\NormalTok{my\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      name age score     gender
## 1   Alice  25 95.65     Female
## 2     Bob  30 88.12 Non-binary
## 3 Charlie  22 75.33       Male
\end{verbatim}

Let's say I noticed I mixed up the genders, and that Bob is Male and Charlie is Non-Binary. Just like we can rewrite a variable, we can also rewrite a column using this approach:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df}\SpecialCharTok{$}\NormalTok{gender }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Female"}\NormalTok{, }\StringTok{"Male"}\NormalTok{, }\StringTok{"Non{-}binary"}\NormalTok{)}

\CommentTok{\#let\textquotesingle{}s see if we have successfully rewritten the Gender Column}

\NormalTok{my\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      name age score     gender
## 1   Alice  25 95.65     Female
## 2     Bob  30 88.12       Male
## 3 Charlie  22 75.33 Non-binary
\end{verbatim}

\paragraph{Adding Rows}\label{adding-rows}

What about if we recruited more participants and wanted to add them to our data frame (it is pretty small at the moment)? This is slightly more complicated, especially when we are dealing with data frames where each column (vector) is of a different data type.

What we need to do is actually create a new data frame that has the same columns as our original data frame. And this new data frame will contain the new row(s) we want to add.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_row }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{name =} \StringTok{"John"}\NormalTok{, }\AttributeTok{age =} \DecValTok{30}\NormalTok{, }\AttributeTok{score =} \FloatTok{77.34}\NormalTok{, }\AttributeTok{gender =} \StringTok{"Male"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Once we have this new data frame we can use the \textbf{\texttt{rbind()}} function to add the new row to your original data frame. \textbf{\texttt{rbind}} takes in two data frames and combines them together. The syntax is as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(my\_df, new\_row)}

\NormalTok{my\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      name age score     gender
## 1   Alice  25 95.65     Female
## 2     Bob  30 88.12       Male
## 3 Charlie  22 75.33 Non-binary
## 4    John  30 77.34       Male
\end{verbatim}

There is one important thing to note when adding rows. There must be the same amount of columns as in the original data frame. Otherwise you will get an error. See what happens when I try to add the following new row to our data frame without adding the score column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_row2 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{name =} \StringTok{"Eric"}\NormalTok{, }\AttributeTok{age =} \DecValTok{34}\NormalTok{, }\AttributeTok{gender =} \StringTok{"Non{-}binary"}\NormalTok{)}

\NormalTok{my\_df }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(my\_df, new\_row2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in rbind(deparse.level, ...): numbers of columns of arguments do not match
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      name age score     gender
## 1   Alice  25 95.65     Female
## 2     Bob  30 88.12       Male
## 3 Charlie  22 75.33 Non-binary
## 4    John  30 77.34       Male
\end{verbatim}

The names in this error message refers to the names of the columns (in this example, name, age, scores, and gender). Since our new\_row2 is missing a column name that is in my\_df, we cannot add this row to the column.

But what if we don't have a score for Eric? Is there no way to add his result to our data frame? There is. All we need to do is add the column \texttt{score} in our \texttt{new\_row2}, but give it the value of \texttt{NA}. The term \texttt{NA} basically means Not Available - as in we don't know the value for this variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_row2 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{name =} \StringTok{"Eric"}\NormalTok{, }\AttributeTok{age =} \DecValTok{34}\NormalTok{, }\AttributeTok{score =} \ConstantTok{NA}\NormalTok{, }\AttributeTok{gender =} \StringTok{"Non{-}binary"}\NormalTok{)}

\NormalTok{my\_df }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(my\_df, new\_row2)}

\NormalTok{my\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      name age score     gender
## 1   Alice  25 95.65     Female
## 2     Bob  30 88.12       Male
## 3 Charlie  22 75.33 Non-binary
## 4    John  30 77.34       Male
## 5    Eric  34    NA Non-binary
\end{verbatim}

NA values can be quite common in real life datasets - sometimes data goes missing! But we'll come back to the concept of NA later on in this course and we will learn a variety of ways to deal with them.

\section{Summary}\label{summary-1}

That concludes this session. Well done, we did a lot of work today. We learned more about the relationship between the console and the script and how we need to be precise when writing commands. We introduced the different types of data that R stores and how those data types can be stored in single lines of data in vectors or combined together in a table in a \textbf{\texttt{data\ frame}}.

Don't feel like you need to have mastered or even remembered all the material that we covered today. Even though these concepts are labeled as ``basic,'' that does not mean they are intuitive. It will take time for them to sink in, and that's normal. We'll drill these concepts a bit further next week. We'll also learn how to import \textbf{\texttt{data\ frames}}, which will set us up nicely for working with the type of data sets we see in Psychological research.

\section{Glossary}\label{glossary-1}

This glossary defines key terms introduced in Chapter 3.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Assignment & The process of assigning a value to a variable using the assignment operator (\texttt{\textless{}-} or \texttt{=}). \\
Character & A data type representing text or strings of characters. \\
Data Frame & A two-dimensional data structure in R that resembles a table with rows and columns. It can store mixed data types. \\
Data Type & The classification of data values into categories, such as numeric, logical, integer, or character. \\
Element & An individual item or value within a data structure, such as a character in a vector. \\
Index & A numerical position or identifier used to access elements within a vector or other data structures. \\
Indexing & The process of selecting specific elements from a data structure using their index values. \\
Integer & A data type representing whole numbers without decimals. \\
Logical & A data type representing binary values (TRUE or FALSE), often used for conditions and logical operations. \\
Numeric & A data type representing numeric values, including real numbers and decimals. \\
Object & A fundamental data structure in R that can store data or values. Objects can include vectors, data frames, and more. \\
Subsetting & The technique of selecting a subset of elements from a data structure, such as a vector or data frame, based on specific criteria. \\
Variable & A named storage location in R that holds data or values. It can represent different types of information. \\
Vector & A one-dimensional data structure in R that can hold multiple elements of the same data type. \\
\end{longtable}

\section{Variable Name Table}\label{variable-name-table}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2603}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2466}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2466}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2466}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Incorrect Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Correct Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Variable names can only contain uppercase alphabetic characters A-Z, lowercase a-z, numeric characters 0-9, periods ., and underscores \_. & Strict & 1st\_name & first\_name \\
Variable names must begin with a letter or a period. & Strict & \_1stname & .firstname \\
Avoid using spaces in variable names. & Strict & my name & my\_name \\
Variable names are case-sensitive. & Strict & my\_name == my\_Name & my\_Name == my\_Name \\
Variable names cannot include special words reserved by R. & Strict & print & to\_print \\
Choose informative variable names that clearly describe the information they represent. & Recommended & money & income \\
Opt for short variable names when possible. & Recommended & date\_of\_birth & dob \\
Prioritize clarity over brevity. & Recommended & tem & total\_exam\_marks \\
Avoid starting variable names with a capital letter. & Recommended & FirstName & firstName \\
Choose a consistent naming style and stick to it. & Recommended & myName, last\_Name & my\_name, last\_name or myName and lastName \\
\end{longtable}

\chapter{\texorpdfstring{\textbf{Programming Fundamentals in R (Part II)}}{Programming Fundamentals in R (Part II)}}\label{programming2}

Today, we are going to build upon the foundational concepts introduced last week and delve deeper into the world of R programming.

By the end of this session, you should be capable of the following:

\begin{itemize}
\item
  Understanding the logic of functions, including how and why they are created.
\item
  Being capable of enhancing your RStudio experience by installing and loading packages.
\item
  Importing and exporting datasets using R.
\end{itemize}

\section{How to read this chapter}\label{how-to-read-this-chapter-1}

If you are reading this chapter. I recommend that you type out every piece of code that I show on the screen, even the code with errors. The reason for this is that it will increase your comfortably with using R and RStudio and writing code. You can then test your understanding in the activities.

\section{Activities}\label{activities-1}

There are several activities associated with this chapter. \href{https://ryandonovan.quarto.pub/week-3---activities-fb08/}{You can find them by clicking this link.}

\section{Functions}\label{functions}

In the previous sessions, we used several functions, like \texttt{print()}, \texttt{head()}, \texttt{View()}, \texttt{mean()}, \texttt{sd()}, \texttt{summary()}, \texttt{aggregate()}, \texttt{plot()}, \texttt{pdf()}, \texttt{class()}, and \texttt{c()}. Each of these functions performs a specific task: they take input (e.g., data or a variable), process it, and return an output. In a way, you can think of functions as action words---like verbs---that tell R to do something.

But what exactly \emph{are} functions? Where do they come from?

Functions are basically a set of pre-written instructions that perform a specific task. Every function we'll use in this course has been written by someone else (or a group of people) and shared within the R community.

You might think getting good at R means memorising loads of functions and knowing exactly what each one does. Sure, that helps. But the real secret to improving at programming is understanding \emph{how} functions work and how to create your own. Once you get that, you won't just use existing functions more effectively---you'll also be able to write your own custom functions when you need them.

Let's learn how to create our own function to get a better feel for how they work.

\subsection{\texorpdfstring{\textbf{The Syntax for Creating a Function}}{The Syntax for Creating a Function}}\label{the-syntax-for-creating-a-function}

Creating a function is a bit like creating a variable.

When we make a variable, we give it a name (e.g., \texttt{my\_name}) and assign (\texttt{\textless{}-}) some information to it (e.g., \texttt{"Ryan"}). Then, we can use that variable wherever we need it, like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_name }\OtherTok{\textless{}{-}} \StringTok{"Ryan"}

\FunctionTok{print}\NormalTok{(my\_name)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Ryan"
\end{verbatim}

When we create a function, we give it a name (e.g., \texttt{my\_function}) and assign a set of instructions to it. Once we've done that, we can call the function whenever we need to, instead of writing out the same code over and over again.

Here's the syntax for creating a function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_function }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(input) \{}
\NormalTok{  instruction1}
\NormalTok{  instruction2}
\NormalTok{  ...}
\NormalTok{  instruction3}
  \FunctionTok{return}\NormalTok{(output) }\CommentTok{\# Return the result}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Let's break this down:

\begin{itemize}
\item
  \textbf{Naming the Function} -- We give our function a name (e.g., \texttt{my\_function}) and use \texttt{\textless{}-} to assign something to it. Just like with variables, this tells R that the name will now store something.
\item
  \textbf{Telling R It's a Function} -- We write \texttt{function()} to let R know we're creating a function, not just storing data. Inside the parentheses \texttt{()}, we can include input information (also called an \emph{argument}). Arguments are just placeholders for values that the function will use later.
\item
  \textbf{Writing the Instructions} -- Inside the curly brackets \texttt{\{\}}, we write the actual steps the function should follow. Some functions only need one step, while others might have multiple.
\item
  \textbf{Returning the Output} -- To make the function give us a result, we use \texttt{return()}. Whatever we include inside \texttt{return()} will be the final output that R displays.
\end{itemize}

This might still seem a bit abstract, so let's go through a concrete example.

\subsection{Creating a Simple Function (1-Argument)}\label{creating-a-simple-function-1-argument}

\subsubsection{\texorpdfstring{\textbf{Defining the Function}}{Defining the Function}}\label{defining-the-function}

You may be surprised to hear that I'm not much of a chef. One big reason is that recipes confuse me with measurements like ``1 cup,'' ``10 ounces,'' or preheating an oven to ``1000 degrees Fahrenheit.'' Wouldn't it be great if we could automate these conversions?

That's where functions come in handy!

Let's create a simple function that converts cups to grams. We'll call it \texttt{cups\_to\_grams}. When naming functions, it's best to pick a name that clearly describes what the function does---it makes your code much easier to read and understand later.

Here's how we start:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cups\_to\_grams }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cups) \{}
  
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{\emph{What's Happening Here?}}

\begin{itemize}
\item
  Inside \textbf{\texttt{function()}}, we've written \textbf{\texttt{cups}}, which is the input or \emph{argument}. Think of it as a placeholder for the value we want to use later.
\item
  Right now, our function doesn't do anything because we haven't given it any instructions yet. Let's fix that.
\end{itemize}

\subsubsection{Writing the Instructions}\label{writing-the-instructions}

According to the metric system, 1 cup is approximately 250 grams. So, our function needs to multiply the number of cups by 250.

Let's add this instruction:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cups\_to\_grams }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cups) \{}
\NormalTok{  grams }\OtherTok{\textless{}{-}}\NormalTok{ cups }\SpecialCharTok{*} \DecValTok{250}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We've created a variable called \texttt{grams} inside the function. It stores the result of \texttt{cups\ *\ 250}.

But there's still one problem---if we run this function, nothing will actually be displayed on the screen. That's because we haven't told R to return the result yet.

\subsubsection{\texorpdfstring{\textbf{Returning the Output}}{Returning the Output}}\label{returning-the-output}

Here's the final version of our function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cups\_to\_grams }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cups) \{}
\NormalTok{  grams }\OtherTok{\textless{}{-}}\NormalTok{ cups }\SpecialCharTok{*} \DecValTok{250}
  \FunctionTok{return}\NormalTok{(grams)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The \texttt{return()} function tells R to keep the value of \texttt{grams} and print it out in the console.

Now, let's see if it works!

\subsection{\texorpdfstring{\textbf{Calling the Function}}{Calling the Function}}\label{calling-the-function}

Calling a function is just like using any of the built-in functions we've used before. We type the function's name and provide an input inside the parentheses.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cups\_to\_grams}\NormalTok{(}\AttributeTok{cups =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 250
\end{verbatim}

This tells R: ``Take \textbf{1 cup}, multiply it by 250, and give me the result.'' The output should be \textbf{250 grams}.

\subsubsection{Using the Function with Different Inputs}\label{using-the-function-with-different-inputs}

You can call the function multiple times with different values:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cups\_to\_grams}\NormalTok{(}\AttributeTok{cups =} \DecValTok{4}\NormalTok{)    }\CommentTok{\# 4 cups = 1000 grams}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cups\_to\_grams}\NormalTok{(}\AttributeTok{cups =} \DecValTok{2}\NormalTok{)    }\CommentTok{\# 2 cups = 500 grams}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 500
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cups\_to\_grams}\NormalTok{(}\AttributeTok{cups =} \FloatTok{1.5}\NormalTok{)  }\CommentTok{\# 1.5 cups = 375 grams}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 375
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cups\_to\_grams}\NormalTok{(}\AttributeTok{cups =} \DecValTok{5}\DataTypeTok{L}\NormalTok{)   }\CommentTok{\# 5 cups = 1250 grams}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1250
\end{verbatim}

\subsubsection{\texorpdfstring{\textbf{Defining the Argument Outside the Function}}{Defining the Argument Outside the Function}}\label{defining-the-argument-outside-the-function}

Instead of passing the value directly inside the function, you can also define it separately and then use it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cups }\OtherTok{=} \DecValTok{2}
\FunctionTok{cups\_to\_grams}\NormalTok{(cups)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 500
\end{verbatim}

\subsubsection{Key Takeaways}\label{key-takeaways}

\begin{itemize}
\item
  This is an example of a \textbf{1-argument function} because it only takes in one input (\textbf{\texttt{cups}}).
\item
  The placeholder (\textbf{\texttt{cups}}) makes the function reusable. It doesn't assume what the input would be ahead of time, so you can use it with any value.
\end{itemize}

One of the most powerful features of functions is that it can take multiple input values, or multiple arguments. In the next section, we'll learn how to create functions with multiple arguments.

\subsection{Creating a Multi-Argument Function}\label{creating-a-multi-argument-function}

A \textbf{multi-argument function} is a function that takes \emph{more than one input} to perform its task. These inputs are called \textbf{arguments}, and they allow the function to work with different pieces of information.

For example, imagine you're making pancakes. You need flour, sugar, baking powder, and butter to bake them. Each of these ingredients is like an argument --- the recipe (function) needs all of them to do its job properly.

The process for creating a one-argument function is practically identical to creating a multi-argument function. The only difference is that we need to enter into more than one input when we define the function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_function }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(input1, input2, input...}\DecValTok{3}\NormalTok{) \{}
\NormalTok{  instruction1}
\NormalTok{  instruction2}
\NormalTok{  ...}
\NormalTok{  instruction3}
  \FunctionTok{return}\NormalTok{(output) }\CommentTok{\# Return the result}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Let's create a function called \texttt{average\_score()} that calculates the average score on a psychological test when given the total score and the number of test items.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{average\_score }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(total\_score, num\_items) \{}
  \CommentTok{\# Calculate the average}
\NormalTok{  average }\OtherTok{\textless{}{-}}\NormalTok{ total\_score }\SpecialCharTok{/}\NormalTok{ num\_items}
  
  \CommentTok{\# Return the average}
  \FunctionTok{return}\NormalTok{(average)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

You can see we have provided two inputs \texttt{total\_score} and \texttt{num\_items} inside \texttt{function()}. This tells R that it should expect multiple inputs when this function is called. Again, we have not defined what the values of \texttt{total\_score} or \texttt{num\_items} is ahead of time, because we want our function to be reusable and adaptable.

Let's give our function a test drive with multiple different possible input values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{average\_score}\NormalTok{(}\AttributeTok{total\_score =} \DecValTok{30}\NormalTok{, }\AttributeTok{num\_items =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{average\_score}\NormalTok{(}\AttributeTok{total\_score =} \DecValTok{40}\NormalTok{, }\AttributeTok{num\_items =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{average\_score}\NormalTok{(}\AttributeTok{total\_score =} \DecValTok{78}\NormalTok{, }\AttributeTok{num\_items =} \DecValTok{17}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.588235
\end{verbatim}

The function carries out the same set instructions regardless of what values we insert for \texttt{total\_score} and \texttt{num\_items}.

\subsubsection{What Happens if I Don't Name the Inputs?}\label{what-happens-if-i-dont-name-the-inputs}

You don't always need to name the arguments when calling the function \emph{as long as} you provide them in the correct order. For example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{average\_score}\NormalTok{(}\DecValTok{65}\NormalTok{, }\DecValTok{5}\NormalTok{) }\CommentTok{\#what happens if I do not write out the input variable names?}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 13
\end{verbatim}

This works because R remembers the order of the inputs (\texttt{total\_score} first, then \texttt{num\_items}).

However, what if you mix up the order of the inputs?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{average\_score}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{65}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.07692308
\end{verbatim}

The function still runs, but the result is wrong. Why? Because R doesn't have common sense --- it doesn't know you meant to input the \texttt{total\_score} as \texttt{65} and the \texttt{num\_items} as \texttt{5}. It blindly follows the order you gave.

To avoid this kind of mistake, it's a good idea to \textbf{specify the names of your input variables} when calling a function. This way, you make your code clearer and less prone to errors. It's also great practice when sharing your code with others --- naming the inputs makes your code more readable, especially if someone hasn't seen the function before.

\subsection{Some Important Features about Functions}\label{some-important-features-about-functions}

Before we finish up on functions, there are some important features about functions that you should know. Namely, the difference between Global and Local Variables, the ability to set and override Default Arguments or inputs, and the ability to search for help on functions in R (and why it's not always the best idea).

\subsubsection{Global vs Local Variables}\label{global-vs-local-variables}

When working with R, it's important to understand that variables you define \emph{inside} a function are treated differently from those you define \emph{outside} a function. Here's the key idea:

\begin{itemize}
\item
  Variables defined \textbf{inside a function} are called \textbf{\emph{local variables}}. They only exist while the function is running and can't be seen or used anywhere else.
\item
  Variables defined \textbf{outside a function} are called \textbf{\emph{global variables}}. These can be used anywhere in your script, including inside functions.
\end{itemize}

Again this is all abstract and boring, so let's use an example.

I'm going to create a simple function called \texttt{my\_favourite\_number\_generator()}. This function will always tell you my favourite number (spoiler: it's 7). It's not the most useful function in the world, but it'll help us understand local and global variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_favourite\_number\_generator }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{  my\_favourite\_number }\OtherTok{\textless{}{-}} \DecValTok{7}  \CommentTok{\# This is a local variable}
  \FunctionTok{return}\NormalTok{(my\_favourite\_number)  }\CommentTok{\# The function returns 7}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here's what's happening:

\begin{itemize}
\item
  I define the variable \texttt{my\_favourite\_number} \emph{inside} the function. This makes it a local variable --- it only exists while the function is running.
\item
  When I call the function, it will return the value of the local variable (\texttt{7}).
\end{itemize}

Let's try it out:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{my\_favourite\_number\_generator}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

It prints \texttt{7}, just as expected.

Now, let's see what happens when I define a global variable called \texttt{my\_favourite\_number} \emph{outside} the function, and then call the function again:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_favourite\_number }\OtherTok{\textless{}{-}} \DecValTok{10}
\FunctionTok{my\_favourite\_number\_generator}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

Even though we defined \texttt{my\_favourite\_number} globally as \texttt{10}, the function still returns \texttt{7}. Why? Because the function uses its \emph{local} version of \texttt{my\_favourite\_number} --- it doesn't care about the global variable.

Finally, let's check what happens if we print the global variable after calling the function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_favourite\_number }\OtherTok{\textless{}{-}} \DecValTok{10} \CommentTok{\#global variable}

\FunctionTok{my\_favourite\_number\_generator}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(my\_favourite\_number)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10
\end{verbatim}

The function only works with its \emph{local} variable (\texttt{7}), but the global variable (\texttt{10}) remains unchanged outside the function.

\textbf{Key Takeaway}

\begin{itemize}
\item
  \textbf{Local variables} exist only inside the function and disappear once the function finishes running.
\item
  \textbf{Global variables} exist outside the function and can be used anywhere in your script.
\end{itemize}

If you keep these ideas in mind, you'll avoid common mistakes and better understand how functions work in R!

\subsubsection{Default Arguments}\label{default-arguments}

Default arguments in R are like having a ``backup plan'' for your functions. You can assign a \textbf{default value} to an argument when you define the function. This means that if you don't provide a specific value for that argument when you call the function, R will automatically use the default.

Think of it like ordering coffee at a café. If you don't specify the type of milk you want, they might use regular milk as the default. But if you do specify oat milk, they'll make it with oat milk instead. Default arguments in R work the same way --- you can stick with the default or override it with your own value.

We've actually already seen a default argument in action! Remember the \texttt{sort()} function? By default, it sorts numbers in \textbf{ascending order} (from smallest to largest). But if you add the argument \texttt{decreasing\ =\ TRUE}, it sorts the numbers in \textbf{descending order} (from largest to smallest).

Here's how it works:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rintro\_marks }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{69}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{80}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{86}\NormalTok{, }\DecValTok{88}\NormalTok{, }\DecValTok{92}\NormalTok{, }\DecValTok{71}\NormalTok{)}

\CommentTok{\# Using the default (ascending order)}
\FunctionTok{sort}\NormalTok{(rintro\_marks)  }\CommentTok{\# Output: 65, 69, 71, 77, 80, 86, 88, 92}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 65 69 71 77 80 86 88 92
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Overriding the default to sort in descending order}
\FunctionTok{sort}\NormalTok{(rintro\_marks, }\AttributeTok{decreasing =} \ConstantTok{TRUE}\NormalTok{)  }\CommentTok{\# Output: 92, 88, 86, 80, 77, 71, 69, 65}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 92 88 86 80 77 71 69 65
\end{verbatim}

In this example:

\begin{itemize}
\item
  The default value of \texttt{decreasing} is \texttt{FALSE.} Unless we change it, it will sort from smallest to largest.
\item
  By specifying \texttt{decreasing\ =\ TRUE}, we override the default and sort from largest to smallest.
\end{itemize}

Now, let's write our own function that uses a default argument. Imagine I want a function called \texttt{greet()} that says hello to someone. If I don't specify who to greet, the function will say ``Hello, World!'' by default.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Function with a default argument}
\NormalTok{greet }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(}\AttributeTok{name =} \StringTok{"World"}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Hello,"}\NormalTok{, name))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here's what happens when we call the function:

\textbf{Using the default value:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calling the function without providing arguments}
\FunctionTok{greet}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Hello, World"
\end{verbatim}

\begin{itemize}
\item
  Since we didn't specify a name, the function used the default value of \texttt{"World"}.
\item
  \textbf{Overriding the default value:}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{greet}\NormalTok{(}\AttributeTok{name =} \StringTok{"Ryan"}\NormalTok{) }\CommentTok{\#please feel free to type in your own name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Hello, Ryan"
\end{verbatim}

By specifying \texttt{name\ =\ "Ryan"}, we told the function to use \texttt{"Ryan"} instead of the default \texttt{"World"}.

\subsection{How to Search for Help on Functions in R}\label{how-to-search-for-help-on-functions-in-r}

When learning R, you'll often come across functions that you don't fully understand or need more details about. Thankfully, R has built-in tools to help you learn how functions work and how to use them properly.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Using the \texttt{?} Operator}
\end{enumerate}

The easiest way to find help for a specific function is to type a \texttt{?} followed by the name of the function. This will bring up the function's help page, which includes:

\begin{itemize}
\item
  A description of what the function does.
\item
  A list of arguments the function takes.
\item
  Examples of how to use the function.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?mean}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Using \texttt{help()}}
\end{enumerate}

Another way to access a function's help page is by using the \texttt{help()} function. This works the same way as the \texttt{?} operator.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{help}\NormalTok{(mean)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Searching for Keywords with \texttt{??}}
\end{enumerate}

If you don't know the exact name of a function but have a general idea of what you're looking for, you can use \texttt{??} followed by a keyword. This searches through R's documentation for functions or topics related to that keyword.

Example:

If you're looking for functions related to ``regression'':

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{??regression}
\end{Highlighting}
\end{Shaded}

This will show you a list of related functions and packages.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Using the Help Tab in RStudio}
\end{enumerate}

If you're using RStudio, the \textbf{Help} tab (in the bottom-right panel) is a great resource. You can:

\begin{itemize}
\item
  Search for a function or topic in the search bar.
\item
  Browse R documentation for built-in functions and packages.
\item
  View the help page for any function you're working with.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  \textbf{Online Resources}
\end{enumerate}

If the built-in documentation isn't enough, you can find additional help online:

\begin{itemize}
\item
  \textbf{R Documentation website}: \url{https://rdocumentation.org}
\item
  \textbf{Stack Overflow}: A forum where R users ask and answer questions.
\item
  \textbf{CRAN Vignettes}: Many R packages include detailed tutorials or ``vignettes'' that explain how to use them. You can search for these on CRAN (\href{https://cran.r-project.org}{https://cran.r-project.org)}).
\end{itemize}

\subsubsection{\texorpdfstring{\textbf{When R's Help Pages Are Difficult to Understand}}{When R's Help Pages Are Difficult to Understand}}\label{when-rs-help-pages-are-difficult-to-understand}

While R's built-in help pages are useful, they can sometimes feel overwhelming, especially for beginners. The language might be too technical, or the examples might not clearly show what you need. If this happens, don't worry --- it's very common (I still come across help pages that I don't understand), and there are plenty of other ways to find help.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Googling for Help}
\end{enumerate}

When the help page doesn't make sense, a quick Google search can often provide more beginner-friendly explanations or practical examples. Here's how to effectively search for help online:

\begin{itemize}
\item
  Include the function name and the word ``R'' in your search query.

  For example:

\begin{Shaded}
\begin{Highlighting}[]
\StringTok{"mean function R example"}
\end{Highlighting}
\end{Shaded}
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{YouTube and Tutorials}
\end{enumerate}

Sometimes, written documentation isn't enough. Watching a tutorial on YouTube can be incredibly helpful for visual learners. Search for:

\begin{itemize}
\item
  ``{[}function name{]} in R tutorial''
\item
  ``How to use {[}function name{]} in R''
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Ask Us}
\end{enumerate}

We are here to help!

\subsection{PSA: Don't Feel Frustrated}\label{psa-dont-feel-frustrated}

It's important for students to know that \emph{nobody memorises everything in R}. Even experienced programmers regularly Google or use forums to find help. We do it all the time. The goal is not to memorise everything but to know how to find the resources you need.

\section{R Packages}\label{r-packages}

Throughout this course, we've been exploring the tools that come with \textbf{base R}, which is the version of R you get right out of the box. Base R provides many useful functions for tasks like data analysis and visualisation. However, one of the biggest advantages of R is that you can expand its capabilities significantly by using \textbf{packages}.

Think of packages like apps on your phone. When you first set up your phone, it comes with essential apps like a web browser and maps. But you'd missing out on a lot of the potential for your smartphone if you only used the basic applications. To make more use of your phone, you might download additional apps like Spotify or Netflix.

Similarly, R packages allow you to ``install'' extra features for R, created by the R community, that can make your programming life much easier.

\subsection{What Are R Packages?}\label{what-are-r-packages}

R packages are \textbf{add-ons} that extend the functionality of R. They often contain:

\begin{itemize}
\item
  \textbf{Functions}: Special tools to make tasks easier (e.g., functions to visualise data or run statistical tests).
\item
  \textbf{Datasets}: Pre-loaded data that you can use for practice.
\item
  \textbf{Documentation}: Guides on how to use the package.
\end{itemize}

R packages are created by people in the R community and shared for free. They're often designed to solve specific problems, such as making a statistical test easier to run or creating beautiful graphs. By using R packages, you benefit from the hard work and expertise of others --- in a sense, you're standing on the shoulders of R giants.

\subsection{Installing and Loading R Package}\label{installing-and-loading-r-package}

One of the most important things to know about R packages is that you first need to install them on your computer. Once installed, you will not need to install them again\footnote{There are a couple of important exceptions to this rule.

  Firslty, If you are creating R projects on your own personal computers using the \texttt{renv} option (which we did), this basically partitions your R project into its own little self-contained space on your computer where it will operate. So when you download and install R packages in that project, they will only exist in that location on your computer (i.e.~your project). You won't need to install packages on that project more than once. However, if you set up a new project, and you need the same packages, then you will need to install those packages on that new project.

  This is equivalent to having separate user accounts on your desktop. If I install something on my account, that doesn't mean it will be installed on your account.

  Secondly, the same holds true for Posit Cloud. In Posit Cloud, every new R project you make will be self-contained, so any packages you install in one project will not transfer over to other projects.}.

However, if you want to use a package, then you will need to load it while you are in RStudio. Every time you open RStudio after closing it, you will need to load that package again if you want to use it.

We do something similar when we download apps on our phone. Once you download Spotify, you don't need to install it again and again every time you want to use it. However, if you do want to use it, you will need to open (i.e.~load) the application.

\subsubsection{Installation}\label{installation}

We are going to install three packages - pwr, jmv, and praise. We will be using jmv and pwr packages later on in the course, but we will install them for now. The praise package provides users with, well, praise. And the pwr package will spit out statistic and programming quotes at you. It's not particularly useful, other than demonstrating the process of loading packages.

There are two main ways to install packages in R:

\textbf{Using the RStudio Interface:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Look for the \textbf{Packages} tab in the bottom-right pane of RStudio.
\item
  Click the ``Install'' button above the list of installed packages.
\item
  In the pop-up window, type the name of the package (e.g., \texttt{pwr}) and make sure ``Install dependencies'' is checked.
\item
  Click ``Install.'' You'll see messages in the console that indicate the installation process.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}} \FunctionTok{install.packages}\NormalTok{(}\StringTok{"pwr"}\NormalTok{)}
\NormalTok{trying URL }\StringTok{\textquotesingle{}https://cran.rstudio.com/bin/macosx/big{-}sur{-}x86\_64/contrib/4.3/rio\_1.0.1.tgz\textquotesingle{}}
\NormalTok{Content type }\StringTok{\textquotesingle{}application/x{-}gzip\textquotesingle{}}\NormalTok{ length }\DecValTok{591359} \FunctionTok{bytes}\NormalTok{ (}\DecValTok{577}\NormalTok{ KB)}
\SpecialCharTok{==}\ErrorTok{================================================}
\NormalTok{downloaded }\DecValTok{577}\NormalTok{ KB}


\NormalTok{The downloaded binary packages are }\ControlFlowTok{in}
    \SpecialCharTok{/}\NormalTok{var}\SpecialCharTok{/}\NormalTok{folders}\SpecialCharTok{/}\NormalTok{h8}\SpecialCharTok{/}\DecValTok{8}\NormalTok{sb24v\_x2lg51cg2z7q8fk3w0000gp}\SpecialCharTok{/}\NormalTok{T}\SpecialCharTok{/}\ErrorTok{/}\NormalTok{RtmpvaY1Ue}\SpecialCharTok{/}\NormalTok{downloaded\_packages}
\end{Highlighting}
\end{Shaded}

Don't worry about the ``scary'' red text --- it's normal and means the package is being installed correctly.

\textbf{Using R Commands:}

You can also install packages directly by typing the \texttt{install.packages()} command in the console. For example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"package name"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The important thing here is that whatever goes inside the parentheses is inside quotation marks.

You can even install multiple packages at once:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"jmv"}\NormalTok{, }\StringTok{"praise"}\NormalTok{))}


\NormalTok{trying URL }\StringTok{\textquotesingle{}https://cran.rstudio.com/bin/macosx/big{-}sur{-}x86\_64/contrib/4.3/praise\_1.0.0.tgz\textquotesingle{}}
\NormalTok{Content type }\StringTok{\textquotesingle{}application/x{-}gzip\textquotesingle{}}\NormalTok{ length }\DecValTok{16537} \FunctionTok{bytes}\NormalTok{ (}\DecValTok{16}\NormalTok{ KB)}
\SpecialCharTok{==}\ErrorTok{================================================}
\NormalTok{downloaded }\DecValTok{16}\NormalTok{ KB}

\NormalTok{trying URL }\StringTok{\textquotesingle{}https://cran.rstudio.com/bin/macosx/big{-}sur{-}x86\_64/contrib/4.3/pwr\_1.5{-}4.tgz\textquotesingle{}}
\NormalTok{Content type }\StringTok{\textquotesingle{}application/x{-}gzip\textquotesingle{}}\NormalTok{ length }\DecValTok{208808} \FunctionTok{bytes}\NormalTok{ (}\DecValTok{203}\NormalTok{ KB)}
\SpecialCharTok{==}\ErrorTok{================================================}
\NormalTok{downloaded }\DecValTok{203}\NormalTok{ KB}


\NormalTok{The downloaded binary packages are }\ControlFlowTok{in}
    \SpecialCharTok{/}\NormalTok{var}\SpecialCharTok{/}\NormalTok{folders}\SpecialCharTok{/}\NormalTok{h8}\SpecialCharTok{/}\DecValTok{8}\NormalTok{sb24v\_x2lg51cg2z7q8fk3w0000gp}\SpecialCharTok{/}\NormalTok{T}\SpecialCharTok{/}\ErrorTok{/}\NormalTok{RtmpvaY1Ue}\SpecialCharTok{/}\NormalTok{downloaded\_packages}
\end{Highlighting}
\end{Shaded}

Again the output is rather scary but the sentences ``package `praise' successfully unpacked and MD5 sums checked'' and ``package `pwr' successfully unpacked and MD5 sums checked'' mean that they are successfully installed onto your computer.

\subsection{Loading Packages}\label{loading-packages}

Okay, now to actually use those packages, we will need to load them. Again, I will show you two ways to load packages.

\subsubsection{Loading using RStudio Interface}\label{loading-using-rstudio-interface}

Once a package is installed, you need to \textbf{load it} into your R session using the \texttt{library()} function. You'll need to do this every time you start RStudio and want to use the package.

\textbf{Using the RStudio Interface:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Go to the \textbf{Packages} tab.
\item
  Scroll down to find the package you want (e.g., \texttt{praise}) and tick the checkbox next to its name. This loads the package.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{img/04-praise-loaded.png}
\caption{\label{fig:unnamed-chunk-131}Loading Packages through RStudio Interface}
\end{figure}

You should see something like the following in your R console (don't worry if you get a warning message like mine, or if you don't receive a warning message)

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}} \FunctionTok{library}\NormalTok{(praise)}
\NormalTok{Warning message}\SpecialCharTok{:}
\NormalTok{package ‘praise’ was built under R version }\DecValTok{4}\NormalTok{.}\FloatTok{3.2} 
\end{Highlighting}
\end{Shaded}

\subsubsection{Loading using the R Console Command}\label{loading-using-the-r-console-command}

We can use the same syntax from that R console output to load in packages there. To load in the \texttt{pwr} and \texttt{jmv} packages, you can type each of these into your script and run each one.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(pwr)}
\FunctionTok{library}\NormalTok{(jmv)}
\end{Highlighting}
\end{Shaded}

There is one significant difference between installing and loading packages through code. When you are installing packages, you can install multiple packages in one command. However, you can only load one package at a time

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#This code will work}
\FunctionTok{install.packages}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"package1"}\NormalTok{, }\StringTok{"package2"}\NormalTok{, }\StringTok{"package3"}\NormalTok{)) }


\CommentTok{\#This code will work}
\FunctionTok{library}\NormalTok{(package1)}
\FunctionTok{library}\NormalTok{(package2)}
\FunctionTok{library}\NormalTok{(package3)}


\CommentTok{\#This code will not work}
\FunctionTok{library}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"package1"}\NormalTok{, }\StringTok{"package2"}\NormalTok{, }\StringTok{"package3"}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\subsection{Testing a Package}\label{testing-a-package}

Let's test the \texttt{praise} package, which generates random compliments (not groundbreaking, but fun to use!). After loading the package, run:

\begin{verbatim}
## [1] "You are neat!"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{praise}\NormalTok{() }\CommentTok{\#everytime you run this line of code it gives you a different line of praise}
\CommentTok{\#so don\textquotesingle{}t be worried if your result is different than mine}
\end{Highlighting}
\end{Shaded}

Every time you run \texttt{praise()}, you'll get a different compliment. Try it out!

\subsection{Troubleshooting Common Issues}\label{troubleshooting-common-issues}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Error: ``There is no package called\ldots{}''}
\end{enumerate}

This means the package hasn't been installed. Use \texttt{install.packages("package\_name")} to install it.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Error: ``Package was built under a different version of R''}
\end{enumerate}

This is a warning that your version of R might be out of data. Usually it can be ignored, but if you are unable to use the package, then you will need to download the latest version of R (using the same steps we used to download it in Chapter 2!).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Dependencies Missing}:
\end{enumerate}

If you see a message about missing dependencies, reinstall the package with ``Install dependencies'' checked, or run:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"package\_name"}\NormalTok{, }\AttributeTok{dependencies =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Conflicting Function Names Between Packages}:
\end{enumerate}

If two loaded packages have functions with the same name, R will use the version from the package loaded most recently. You will typically see a message that looks like this in your R console

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Attaching package}\SpecialCharTok{:}\NormalTok{ ‘dplyr’}

\NormalTok{The following objects are masked from ‘package}\SpecialCharTok{:}\NormalTok{stats’}\SpecialCharTok{:}

\NormalTok{    filter, lag}
\end{Highlighting}
\end{Shaded}

\textbf{\emph{Here's what this means:}}

R is informing you that the functions filter and lag from the stats package (which comes with base R) are now ``masked'' by the versions from the dplyr package.

This simply means that if you call filter() or lag() without specifying the package, R will use the version from dplyr because it was loaded most recently.

\textbf{\emph{How to Handle This:}}

If you see this message, it's not an error --- it's just a warning that there's a conflict. To explicitly use a function from a specific package, you can use the :: operator

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stats}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{()  }\CommentTok{\# Use the filter function from stats}
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{()  }\CommentTok{\# Use the filter function from dplyr}
\end{Highlighting}
\end{Shaded}

\subsection{Best Practices for Installing and Loading Packages}\label{best-practices-for-installing-and-loading-packages}

There are important rules to follow when writing code to install and load packages in R.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Load Packages at the Top of Your Script:} Place all \texttt{library()} calls at the very top of your R script. This helps others see which packages are required for your code.
\item
  \textbf{Avoid Running \texttt{install.packages()} in a Script:} Use \texttt{install.packages()} in the console, not in your script. If someone downloads your script and accidentally runs it, it will automatically install the packages on their computer. Generally it's better for people to make a decision themselves on whether they want to install anything on their computer. By not writing the \texttt{install.packages()} command in our script, we give them the power.
\item
  \textbf{Comment Out Install Commands:} If you include \texttt{install.packages()} in your script for documentation purposes, make sure it's commented out:
\end{enumerate}

\begin{figure}
\centering
\includegraphics{img/04-packages-convention.png}
\caption{\label{fig:unnamed-chunk-140}Conventions for Installing and Loading Packages in R Script}
\end{figure}

\subsection{Summary}\label{summary-2}

There you have it. You have successfully installed and loaded your first packages in R. The praise package is not exactly groundbreaking, but we will be coming back to the jmv and pwr packages later on.

\section{Importing and Exporting Data}\label{importing}

While creating data frames and lists in R is valuable, the majority of the data you'll work with in R will likely come from external sources. Therefore, it's essential to know how to import data into R. Similarly, once you've processed and analysed your data in R, you'll often need to export it for further use or sharing.

First, you'll need to download two files: \texttt{psycho.csv}. Both files are available on Canvas.

\subsection{Importing CSV files.}\label{importing-csv-files.}

Comma-Separated Values (CSV) files are a prevalent format for storing tabular data. Similar to Excel files, data in CSV files is organized into rows and columns, with each row representing a single record and each column representing a different attribute or variable.

CSV files are plain text files, making them easy to create, edit, and view using a simple text editor. This simplicity and universality make CSV files a popular choice for data exchange across various applications and platforms.

In a CSV file, each value in the table is separated by a comma (,), hence the name ``comma-separated values.'' However, depending on locale settings, other delimiters such as semicolons (;) or tabs (\textbackslash t) may be used instead.

One of the key advantages of CSV files is their compatibility with a wide range of software and programming languages, including R. They can be effortlessly imported into statistical software for analysis, making them a versatile and widely adopted format for data storage and sharing.

To import the ``psycho.csv'' file, please follow these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Make sure you have download (or uploaded) the ``psycho.csv'' file to your \texttt{week3} folder
\item
  In your script, write and run the following line of code:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{getwd}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "/Users/ryandonovan 1/Desktop/rintro"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{psycho\_df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"datasets/psycho.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Once you have run that line of code, you can have a look at the data frame by using the \texttt{head()} and \texttt{summary()} functions.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(psycho) }\CommentTok{\#this will print out the first six rows}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Participant_ID Treatment Neuroticism
## 1              1   Placebo    39.39524
## 2              2   Placebo    42.69823
## 3              3   Placebo    60.58708
## 4              4   Placebo    45.70508
## 5              5   Placebo    46.29288
## 6              6   Placebo    62.15065
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(psycho) }\CommentTok{\#print out summary stats for each column}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Participant_ID   Treatment          Neuroticism   
##  Min.   : 1.00   Length:60          Min.   :25.33  
##  1st Qu.:15.75   Class :character   1st Qu.:41.75  
##  Median :30.50   Mode  :character   Median :49.44  
##  Mean   :30.50                      Mean   :48.99  
##  3rd Qu.:45.25                      3rd Qu.:54.61  
##  Max.   :60.00                      Max.   :76.69
\end{verbatim}

If your results match mine, it means you have correctly imported the data.

\subsection{Exporting Datasets in R}\label{exporting-datasets-in-r}

After analysing and processing your data in R, you may need to export the results to share them with others or use them in other applications. R provides several functions for exporting data to various file formats, including CSV, Excel, and R data files. In this section, we'll explore how to export datasets using these functions.

\subsubsection{Exporting to CSV Files}\label{exporting-to-csv-files}

To export a dataset to a CSV file, we can use the \texttt{write.csv()} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Export dataset to a CSV file using the following syntax}
\FunctionTok{write.csv}\NormalTok{(my\_dataset, }\AttributeTok{file =} \StringTok{"output.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The argument \texttt{file} will create the name of the file and enable you to change the location of the file. The way this is currently written, it will save your file to your working directory. If you need a reminder on how to set and check your working directory \hyperref[set_wd]{click here}. Make sure it is set to the location you want your file to go.

Let's export a copy of our psycho dataframe:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{write.csv}\NormalTok{(psycho, }\AttributeTok{file =} \StringTok{"psycho\_copy.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In your working directory (check the Files pane), you should see the file \texttt{psycho\_copy.csv}. If you go to your file manager system on your computer or on Posit Cloud, find the file, and open it, the file should open in either a text or Excel file.

\section{Summary}\label{summary-3}

Congratulations, you've made it through Programming Part I and II! We've covered a lot of useful (but let's be honest, not exactly riveting) concepts in programming with R. Throughout these sections, we've learned how R categories data, stores it in data structures, converts data types, and creates variables and functions. Additionally, we've explored how to install and load packages to enhance R's capabilities, and how to import and export data.

For the next few weeks, we will focus on using R to run descriptive and inferential statistical analysis.

\section{Glossary}\label{glossary-2}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3099}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6901}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Term}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Definition}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
CSV & Comma-Separated Values: a common file format for storing tabular data, where each value is separated by a comma. \\
SPSS & Statistical Package for the Social Sciences: software commonly used for statistical analysis, often associated with .sav files. \\
Dataframe & A two-dimensional data structure in R that resembles a table with rows and columns. It can store mixed data types. \\
Importing & The process of bringing data from external sources into R for analysis or manipulation. \\
Exporting & The process of saving data from R to external files or formats for use in other applications. \\
write.csv() & A function in R used to export a dataset to a CSV file. \\
\end{longtable}

\chapter{Descriptive Statistics and T-Tests in R}\label{descriptive-statistics-and-t-tests-in-r}

In this weeks workshop, we are going to learn how to perform descriptive statistics and conduct both independent and paired-samples t-tests (which you covered in today's lecture).

\begin{figure}
\centering
\includegraphics{img/05-T-tests.png}
\caption{A graphical image illustrating the two main types of t-test. The first shows two groups of people with the header ``unpaired-t-test'' and a caption underneath reading ``Is there a difference between two groups''. The second shows the same group of people with a clock between them, the caption ``paired t-test'' and written underneath is ``Is there a difference in a group between two points in time''.}
\end{figure}

Additionally, we will learn how to check parametric assumptions in R. By the end of this session, you will be able to:

\begin{itemize}
\item
  Use the jmv package to run descriptive statistics and check parametric assumptions.
\item
  Conduct an independent samples t-test in R.
\item
  Conduct a paired-samples t-test in R.
\item
  Conduct an apriori power analysis in R for t-tests.
\end{itemize}

\section{How to read this chapter}\label{how-to-read-this-chapter-2}

This chapter aims to supplement your in-lecture learning about t-tests, to recap when and why you might use them, and to build on this knowledge to show how to conduct t-tests in R.

\section{Activities}\label{activities-2}

As in previous sessions there are several activities associated with this chapter. You can find them here or on Canvas under the \textbf{Week 4 module}.

\section{Between-Groups Comparisons}\label{between-groups-comparisons}

For our between group comparisons we will be using the \textbf{wellbeing.csv} data, which we have saved as \textbf{df\_wellbeing}

This data was collected from an experimental study investigating the effects of \textbf{Caffeine} (Low Caffeine, and High Caffeine) on various outcome variables, including experiences of pain, fatigue, depression, and overall wellbeing. Additionally, participants' age and gender were recorded.

After loading the datasets, it's always good practice to inspect it before doing any analyses. You can use the \textbf{head()} function to get an overview of the wellbeing dataset:

\section{Descriptive Statistics}\label{descriptive-statistics}

Descriptive statistics (such as the mean and standard deviation) give us important additional information to the results of our statistical tests. As such it is important to calculate them, and to include them in your write-up.

\subsection{Writing up the results of an independent samples t-test}\label{writing-up-the-results-of-an-independent-samples-t-test}

\textbf{The results of a t-test are typically written up as such:}

A Welch independent samples t-test was perfomed and \textbf{a} / \textbf{no} significant difference on performance was found between group A (M= \textbf{Group A mean value}, SD= \textbf{Group A standard deviation}) and group B (M= \textbf{Group B mean value}, SD= \textbf{Group B standard deviation}) on the task t(\textbf{df value})= \textbf{t statistic value}, p=\textbf{exact p value to two or three decimal places}), with a large effect (d= \textbf{Cohen's d to two decimal places}, 95\% CI {[}\textbf{lower bound} ‐ \textbf{higher bound}{]}).

In the associated activities with this chapter (specifically Activity 4) you will learn how to use the descriptives function from the jmv package to get the descriptive statistics you need to fill in the blanks above.

\section{Statistically comparing between 2 groups: Independent samples t-test (unpaired t-test)}\label{statistically-comparing-between-2-groups-independent-samples-t-test-unpaired-t-test}

Let's imagine we're interested in investigating the effects of caffeine consumption on levels of self-reported health. Specifically, we want to determine whether people in the high caffeine condition scored significantly differently from those in the low caffeine condition.

In this case:

Our \textbf{independent variable} is caffeine consumption group (low caffeine vs high caffeine)

Our \textbf{dependent variable} is health

We could specify our hypothesis as such:

\textbf{H1}: We predict there will be statistically significant difference in reported health levels between people in the high versus low caffeine conditions.

\textbf{H0 (Null hypothesis)}: There will not be a statistically significant difference in reported health levels between people in the high versus low caffeine conditions.

Note that as we do not specify which group will have higher/lower health levels this is a \textbf{nondirectional hypothesis}

As we have two independent groups we want to compare, this would be best addressed via an \textbf{independent samples t-test}. Before we can do this, there are a couple of preliminary steps we need to take. First, we need to check the parametric assumptions required for an independent samples t-test.

\begin{figure}
\centering
\includegraphics{img/05-IndependentSamples t-test.png}
\caption{A graphical image which shows two groups of people with the header ``unpaired-t-test'' and a caption underneath reading ``Is there a difference between two groups''.}
\end{figure}

\textbf{Checking our parametric assumptions}

There are several key assumptions for conducting an independent samples t-test. We don't need R to check the first three assumptions (a-c). A quick visual inspection of the dataset and knowledge of the design will tell us whether these are met, and in this case, they are.:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  The dependent variable should be measured on a continuous scale.
\item
  The independent variable should consist of two categorical, independent groups.
\item
  The groups should be independent of each other.
\item
  There should be no significant outliers. We can check this assumption via a boxplot, which will flag any outliers by placing numbers next to them.
\item
  The dependent variable should be approximately normally distributed for each group. We can check this using a Shapiro-Wilk test. When interpreting Shapiro-Wilk A \textbf{significant p-value (p \textless{} 0.05)} means that the \emph{assumption has been violated}, and you cannot run an independent samples t-test. A \textbf{not significant p-value (p \textgreater{} 0.05)} means that the \emph{assumption has been met}, and you can proceed.
\item
  The dependent variable should exhibit homogeneity of variance. We can check this using Levene's Test using the function \emph{levenetest} from the \emph{car} package. The syntax for this is below:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{leveneTest}\NormalTok{(DependentVariable }\SpecialCharTok{\textasciitilde{}}\NormalTok{ IndependentVariable, }\AttributeTok{data =}\NormalTok{ ourdataset)}
\end{Highlighting}
\end{Shaded}

When interpreting Levenes test A \textbf{significant p-value (p \textless{} 0.05)} means that the \emph{assumption has been violated}, and you cannot run an independent samples t-test. A \textbf{not significant p-value (p \textgreater{} 0.05)} means that the \emph{assumption has been met}, and you can proceed.

Activity 5 in the associated Activities for this week will show in detail how to check assumptions d-f.~Once again we will be using the \textbf{descriptives} function for this.

For future reference you could use code like that below to check your assumptions (except for homogeneity of variance) \textbf{and} get your descriptive statistics

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{descriptives}\NormalTok{(dataframe\_name, }\CommentTok{\# our dataset}
             \AttributeTok{vars =} \StringTok{"DV"}\NormalTok{, }\CommentTok{\# our DV}
             \AttributeTok{splitBy =} \StringTok{"IV"}\NormalTok{, }\CommentTok{\# our IV}
             \AttributeTok{ci =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# this outputs confidence intervals to include in your descriptives}
             \AttributeTok{box =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# this outputs boxplots, so you can check for outliers}
             \AttributeTok{sw =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# this conducts a shapiro{-}wilk test to check if our dependent variable is normally distributed }
\end{Highlighting}
\end{Shaded}

If all of the assumptions are met you can proceed to running the independent samples t-test.

We use the \textbf{t.test function} to perform the t-test. The syntax is:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(DV }\SpecialCharTok{\textasciitilde{}}\NormalTok{ IV, }
       \AttributeTok{paired =} \ConstantTok{FALSE}\NormalTok{,}
       \AttributeTok{alternative =} \FunctionTok{c}\NormalTok{(}\StringTok{"two.sided"}\NormalTok{, }\StringTok{"less"}\NormalTok{, }\StringTok{"greater"}\NormalTok{),}
       \AttributeTok{data =}\NormalTok{ ourdataset)}
\end{Highlighting}
\end{Shaded}

In this function:

DV \textasciitilde{} IV specifies the \textbf{dependent variable (DV)} and \textbf{independent variable (IV)}.

\textbf{paired = FALSE} indicates that we are conducting an independent samples t-test. If we were comparing related groups (e.g., pre-test vs.~post-test), we would set paired = TRUE.

The \textbf{alternative} argument specifies the hypothesis test type:

\emph{``two.sided''} tests for any difference between groups.

\emph{``less''} tests whether the first group has a lower mean than the second.

\emph{``greater''} tests whether the first group has a higher mean than the second.

As we have a \textbf{non-directional hypothesis} we will run a \emph{two-sided} t-test on our df\_wellbeing dataset.

Remember that in Psychology we set our alpha level as 0.05. That means that in interpreting the results of your t-test.

If your p value is \textbf{less than} 0.05 (aka p \textless{} 0.05) then you have a \textbf{statistically significant} effect.

If your value is \textbf{greater than} or equal to 0.05 (aka p \textgreater{} 0.05) then you do not have a \textbf{statistically significant} effect

\section{Effect sizes!}\label{effect-sizes}

\begin{figure}
\centering
\includegraphics{img/05-EffectSizes.jpg}
\caption{A picture that says I love effect sizes.}
\end{figure}

The final thing to calculate before writing up the results of our t-test is the effect size. If you recall for t-tests we use Cohen's d as our effect size of interest (helpful visualisation here to recap). Cohen's d has the following rules of thumb for interpretation:

d = 0.2 is a small effect

d = 0.5 is a medium effect

d = 0.8 is a large effect

We can use the below code to calculate the effect size for the independent samples t-test which we ran this week. We need to do a little data wrangling to run this for our paired-samples t-test, which is fine, but we'll come back to it in later weeks.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(effectsize) }\CommentTok{\#that calculates the effect size {-} note we may need to install this package}
\FunctionTok{cohens\_d}\NormalTok{(health }\SpecialCharTok{\textasciitilde{}}\NormalTok{ condition, }\CommentTok{\# DV \textasciitilde{} IV}
              \AttributeTok{paired =} \ConstantTok{FALSE}\NormalTok{, }\CommentTok{\#paired = FALSE for independent samples, but would be true for paired samples t{-}test}
              \AttributeTok{data =}\NormalTok{ df\_wellbeing) }\CommentTok{\# our data}
\end{Highlighting}
\end{Shaded}

\textbf{Writing up the results:}

After following the steps outlined above/in the activities you should be able to fill in the below blanks to write up the results of the independent samples t-test.

A Welch independent samples t-test was perfomed and \textbf{a} / \textbf{no} significant difference on performance was found between group A (M= \textbf{Group A mean value}, SD= \textbf{Group A standard deviation}) and group B (M= \textbf{Group B mean value}, SD= \textbf{Group B standard deviation}) on the task t(\textbf{df value})= \textbf{t statistic value}, p=\textbf{exact p value to two or three decimal places}), with a large effect (d= \textbf{Cohen's d to two decimal places}, 95\% CI {[}\textbf{lower bound} ‐ \textbf{higher bound}{]}).

\section{Within-Subjects Comparisons}\label{within-subjects-comparisons}

For our within-subjects comparisons we will be using the \textbf{reading.csv} data, which we have saved as df\_reading

This data was collected from a reading intervention study investigating the effects of a literacy intervention, comparing the same participants before and after the intervention. As such we will be comparing participants reading at: \textbf{Baseline}, and \textbf{Time2}.

A lot of the steps for conducting within-subjects comparisons are very similar to between-groups comparisons. So we can refer to the above sections for help if we get unsure.

\section{Descriptive Statistics for a paired-samples t-test}\label{descriptive-statistics-for-a-paired-samples-t-test}

A paired-samples t-test was perfomed and \textbf{a} / \textbf{no} significant difference on \textbf{dependent variable} was found between \textbf{Baseline} (M= \textbf{Baseline mean value}, SD= \textbf{Baseline standard deviation}) and \textbf{Time 2} (M= \textbf{Time 2 mean value}, SD= \textbf{Time 2 standard deviation}) on the task t(\textbf{df value})= \textbf{t statistic value}, p=\textbf{exact p value to two or three decimal places}), with a \textbf{large} effect (d= \textbf{Cohen's d to two decimal places}, 95\% CI {[}\textbf{lower bound} ‐ \textbf{higher bound}{]}).

Once again you can use the \textbf{descriptives} function to fill in the descriptive statistics needed above.

Let's imagine we're interested in investigating the effects of our intervention on levels of reading ability. Specifically, we want to determine whether children's reading ability was significantly better at Time 2 (after intervention) compared to at baseline (before the intervention).

In this case:

Our \textbf{independent variable} is time (Baseline vs Time2)

Our \textbf{dependent variable} is reading ability

We could specify our \textbf{hypothesis} as such:

\textbf{H1}: We predict there will be statistically higher reading ability in children at Time 2 (after intervention) than at Baseline.

\textbf{H0 (Null hypothesis)}: There will not be statistically significant higher reading ability in children at Time 2 (after intervention) than at Baseline.

Note that as we do specify which condition will have higher reading ability this is a \textbf{directional hypothesis}

As all participants take part in both conditions (e.g.~are tested at two timepoints), this would be best addressed via a \textbf{paired samples t-test}. Before we can do this, there are a couple of preliminary steps we need to take. First, we need to check the parametric assumptions required for a paired samples t-test.

\begin{figure}
\centering
\includegraphics{img/05-PairedT-Test.png}
\caption{A graphical image which shows the same group of people with a clock between them, the caption ``paired t-test'' and written underneath is ``Is there a difference in a group between two points in time''.}
\end{figure}

Checking our parametric assumptions

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Our dependent variable should be measured on a continuous scale
\item
  The observations are independent of one another
\item
  There should be no significant outliers
\item
  Our dependent variable should be normally distributed
\end{enumerate}

Here, it's only really the outliers and the normal distribution that needs to be evaluated using functions in R, both of which we can assess using the \textbf{descriptives} function. The below code will output the descriptive statistics you need, \textbf{and} check your assumptions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{descriptives}\NormalTok{(df\_reading, }\CommentTok{\# your dataframe name here}
             \AttributeTok{vars =} \FunctionTok{c}\NormalTok{(}\StringTok{"Baseline"}\NormalTok{, }\StringTok{"Time2"}\NormalTok{), }\CommentTok{\# your two conditions / timepoints}
             \AttributeTok{ci =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# this outputs confidence intervals to include in your descriptives}
             \AttributeTok{box =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# this outputs boxplots, so you can check for outliers}
             \AttributeTok{sw =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# this conducts a shapiro{-}wilk test to check if our dependent variable is normally distributed }
\end{Highlighting}
\end{Shaded}

We use the t.test function to perform the t-test. Here the syntax is:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(ourDataset}\SpecialCharTok{$}\NormalTok{Condition1, ourDataset}\SpecialCharTok{$}\NormalTok{Condition2, }\CommentTok{\# here we specify our two conditions         }
       \AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# here we specify that it is a paired samples t{-}test       }
       \AttributeTok{alternative =} \FunctionTok{c}\NormalTok{(}\StringTok{"two.sided"}\NormalTok{, }\StringTok{"less"}\NormalTok{, }\StringTok{"greater"}\NormalTok{)) }\CommentTok{\#here you specify whether the test is directional or nondirectional, dependent on your hypothesis}
\end{Highlighting}
\end{Shaded}

Once you have run the t-test you should have the information to replace the information in bold with the correct information.

A paired-samples t-test was perfomed and \textbf{a} / \textbf{no} significant difference on \textbf{dependent variable} was found between \textbf{Baseline} (M= \textbf{Baseline mean value}, SD= \textbf{Baseline standard deviation}) and \textbf{Time 2} (M= \textbf{Time 2 mean value}, SD= \textbf{Time 2 standard deviation}) on the task t(\textbf{df value})= \textbf{t statistic value}, p=\textbf{exact p value to two or three decimal places}), with a \textbf{large} effect (d= \textbf{Cohen's d to two decimal places}, 95\% CI {[}\textbf{lower bound} ‐ \textbf{higher bound}{]}).

\section{Power analyses}\label{power-analyses}

Now you may recall in your Week 3 lecture Ciara being very enthusiastic about power analyses, and the importance of conducting one before you collect any data (called an a priori or prospective power analysis). There are also power analyses you can conduct after data collection, but there are issues with them, and generally best practice is to do one beforehand (A useful paper if you're interested in learning more).

Here we are going to learn about how to conduct a power analysis for both an independent samples and paired-samples t-test.

As you may recall there are some key pieces of information we need for a power analysis

\begin{itemize}
\item
  Alpha level (typically 0.05 in Psychology and the social sciences)
\item
  The minimum effect size of interest
\item
  Our desired power
\item
  If our test is one or two-tailed (i.e.~do we have a directional or nondirectional hypothesis)
\end{itemize}

Reminder that this \href{https://rpsychologist.com/d3/nhst/}{interactive visualisation} can be helpful in understanding how these things interact.

\section{Power analysis for an independent samples t-test}\label{power-analysis-for-an-independent-samples-t-test}

The syntax for conducting an apriori statistical power analysis for an independent samples t-test is the following:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Conduct power analysis for an independent samples t{-}test}
\FunctionTok{pwr.t.test}\NormalTok{(}\AttributeTok{d =} \FloatTok{0.5}\NormalTok{,         }\CommentTok{\# Your Expected effect size}
           \AttributeTok{sig.level =} \FloatTok{0.05}\NormalTok{, }\CommentTok{\# Significance level}
           \AttributeTok{power =} \FloatTok{0.80}\NormalTok{,     }\CommentTok{\# Desired power level}
           \AttributeTok{type =} \StringTok{"two.sample"}\NormalTok{,  }\CommentTok{\# Indicates an independent t{-}test}
           \AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{)  }\CommentTok{\# Indicates a two{-}tailed test, \#can be changed to "one.sided"}
\end{Highlighting}
\end{Shaded}

\section{Power analysis for a paired-samples t-test}\label{power-analysis-for-a-paired-samples-t-test}

If we want to run a paired samples-test, then we can change the type from ``two.sample'' to ``one.sample'':

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pwr.t.test}\NormalTok{(}\AttributeTok{d =} \FloatTok{0.5}\NormalTok{,         }\CommentTok{\# Your Expected effect size}
           \AttributeTok{sig.level =} \FloatTok{0.05}\NormalTok{, }\CommentTok{\# Significance level}
           \AttributeTok{power =} \FloatTok{0.80}\NormalTok{,     }\CommentTok{\# Desired power level}
           \AttributeTok{type =} \StringTok{"paired"}\NormalTok{,  }\CommentTok{\# Indicates an independent t{-}test}
           \AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{)  }\CommentTok{\# Indicates a two{-}tailed test, \#can be changed to "one.sided"}
\end{Highlighting}
\end{Shaded}

\chapter{Correlation in R}\label{correlation-in-r}

In this weeks workshop, we are going to learn how to perform correlation analyses along with the relevant descriptive statistics and assumption checks.

\includegraphics{img/Corrs.png} By the end of this session, you will be able to:

\begin{itemize}
\item
  Use the jmv package to run descriptive statistics and check assumptions.
\item
  Conduct a simple correlation in R.
\item
  Conduct a multiple correlation R.
\item
  Learn how to make pretty correlation graphs.
\item
  Conduct an apriori power analysis in R for correlations.
\end{itemize}

\section{How to read this chapter}\label{how-to-read-this-chapter-3}

This chapter aims to supplement your in-lecture learning about correlations, to recap when and why you might use them, and to build on this knowledge to show how to conduct correlations in R.

\section{Activities}\label{activities-3}

As in previous sessions there are several activities associated with this chapter. \href{https://ryandonovan.quarto.pub/week5---activities/}{You can find them here} or on Canvas under the \textbf{Week 5 module}.

\section{Correlations}\label{correlations}

Todays data was collected from a cross-sectional study examining the relationship between sleep difficulty, anxiety, and depression.

After loading the datasets, it's always good practice to inspect it before doing any analyses. You can use the head() function to get an overview of the sleep quality dataset:

Now that our environment is set up and our dataset is loaded, we are ready to dive into descriptive statistics \& check our assumptions.

Last week we learned how to use descriptives function to do both of these things.

Let's imagine we're interested in investigating the relationship between depression and anxiety. Specifically we predict that higher levels of depression (as shown by higher scores) will be associated with higher anxiety levels (as shown by higher scores).

\textbf{In this case:}

Our variables are 1) depression and 2) anxiety

We could specify our hypothesis as such:

\textbf{H1:} We predict that higher depression will be positively correlated with higher anxiety scores.

\textbf{H0 (Null hypothesis):} There will not be a significant correlation between depression scores and anxiety scores

Note that as we do specify the direction of the association / correlation that this is a directional hypothesis.

As we are interested in the relationship between two continuous variables, this would be best addressed via a simple correlation. Before we can do this, there are a couple of preliminary steps we need to take. First, we need to check the assumptions required for a correlation.

Remember that for correlations the two main outcomes of interest are \textbf{direction} and \textbf{strength}

\begin{itemize}
\item
  \textbf{Direction}: In a positive correlation one variable goes up as the other does. In a negative correlation as one variable goes up the other goes down.
\item
  \textbf{Strength}: Measured via Pearsons r usually, spans form 0-0.2 (negligible), to 0.9-1 (very strong).
\end{itemize}

\begin{figure}
\centering
\includegraphics{img/StrenDir.png}
\caption{Correlation Strength \& Direction}
\end{figure}

\textbf{Checking our assumptions}

There are two main types of correlation you might use: Pearsons and Spearmans.

\textbf{Pearsons Correlation:} This type of correlation assumes a linear relationship between variables.

\textbf{Spearmans Correlation:} This type of correlation relies on ranks and is more robust against outliers, but is less efficient for large datasets.

For the purposes of this workshop, you would typically use Pearsons correlation, unless the below assumptions are not met.

\textbf{There are several key assumptions for conducting Pearsons simple correlation:}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  The data are continuous, and are either interval or ratio.
\end{enumerate}

\textbf{Interval data:} Data that is measured on a numeric scale with equal distance between adjacent values, that does not have a true zero. This is a very common data type in research (e.g.~Test scores, IQ etc).

\textbf{Ratio data:} Data that is measured on a numeric scale with equal distance between adjacent values, that has a true zero (e.g.~Height, Weight etc).

For the purposes of this workshop we know our two variables are outcomes on a wellbeing test, as such they are interval data and this assumption has been met

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  There is a data point for each participant for both variables.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  To check this assumption we can simply check if there is any missing data, conveniently descriptives automatically tells us this.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The data are normally distributed for your two variables. Reminder that we can use Shapiro Wilks test to test for this: A \textbf{significant p-value (p \textless{} 0.05)} means that the \emph{assumption has been violated}, and you cannot run Pearsons correlation. A \textbf{not significant p-value (p \textgreater{} 0.05)} means that the \emph{assumption has been met}, and you can proceed.
\end{enumerate}

For linear models we also use our qqplot to test for this for now. If the dots follow the line for the residuals then this assumption has been met.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{descriptives}\NormalTok{(df\_sleep, }\CommentTok{\# our data}
             \AttributeTok{vars =} \FunctionTok{c}\NormalTok{(}\StringTok{"Depression"}\NormalTok{, }\StringTok{"Anxiety"}\NormalTok{), }\CommentTok{\# our two variables}
             \AttributeTok{hist =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# this generates a histogram}
             \AttributeTok{sw =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# this runs shapiro{-}wilks test}
             \AttributeTok{qq=}\ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# this generates a qq plot }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  The relationship between the two variables is linear. We can check this assumption via a scatterplot to visualise the 2 variables. The syntax is below:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\AttributeTok{x=}\NormalTok{DataframeName}\SpecialCharTok{$}\NormalTok{Variable1,}\AttributeTok{y=}\NormalTok{DataframeName}\SpecialCharTok{$}\NormalTok{Variable1)}
\end{Highlighting}
\end{Shaded}

If there is a straight line in the dots then we can assume this assumption has been met.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  The assumption of homoscedasticity. For this assumption we could check this visually by to creating a plot of the residuals to test for this. For now however we will use a Breusch-Pagan test (1979). For this test: A \textbf{significant p-value (p \textless{} 0.05)} means that the \emph{assumption has been violated}, and you cannot run Pearsons correlation. A \textbf{not significant p-value (p \textgreater{} 0.05)} means that the \emph{assumption has been met}, and you can proceed.
\end{enumerate}

This test will come up again next week for regressions (As will plotting residuals) but for now to do this we will create a linear model, and then use the function check\_heteroscasticity from the performance package.

If we get a non-significant p-value then the data is homoscedastic and our assumption has been met. The syntax for this is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nameForModel }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(DV }\SpecialCharTok{\textasciitilde{}}\NormalTok{ IV, }\AttributeTok{data =}\NormalTok{ ourDataFrame) }\CommentTok{\# here we are creating an object "nameForModel" which contatins a linear model of our DV \textasciitilde{} IV }
\FunctionTok{check\_heteroscedasticity}\NormalTok{(nameForModel) }\CommentTok{\# this function performs a Breusch{-}Pagan test for our model}
\end{Highlighting}
\end{Shaded}

As we can see our assumptions have been met we can use a Pearson correlation to test our hypotheses.

\textbf{Running the Simple Correlation}

We use the correlation function to perform the correlation. The syntax is:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Remember you need to edit the specific names/variables below to make it work for our data and needs}

\FunctionTok{cor.test}\NormalTok{(DataframeName}\SpecialCharTok{$}\NormalTok{Variable1, DataframeName}\SpecialCharTok{$}\NormalTok{Variable2, }\AttributeTok{method =} \StringTok{"pearson"}\NormalTok{ OR }\StringTok{"spearman"}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{ or }\StringTok{"less"}\NormalTok{ or }\StringTok{"greater"}\NormalTok{)}

\CommentTok{\# alternative specifies whether it\textquotesingle{}s a one or two{-}sided test, or one{-}sided. "greater" corresponds to positive association, "less" to negative association}
\end{Highlighting}
\end{Shaded}

\textbf{Here's how we might write up the results in APA style:}

A Pearsons correlation was conducted to assess the relationship between depression (M= \textbf{Depression Mean}, SD= \textbf{Depression Standard Deviation}) and anxiety scores (M= \textbf{Anxiety Mean}, SD= \textbf{Anxiety Standard Deviation}). The test showed that there was a significant positive correlation between the two variables r(\textbf{degrees of freedom}) = \textbf{Pearsons r}, p = \textbf{p value}. As such we reject the null hypothesis.

\textbf{Multiple Correlations}

Sometimes we're interested in the associations between multiple variables. In todays dataset we have sleep difficulty, optimism, depression, and anxiety. As such we might be interested in the relationship between all four variables.

In addition to our earlier prediction regarding depression and anxiety we could also predict:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  that greater sleep difficulty (as shown by higher values) will be associated with higher anxiety and depression levels (as shown by higher scores).
\item
  that greater optimism (as shown by higher values) will be associated with lower anxiety and depression levels (as shown by lower scores).
\end{enumerate}

In this case:

Our variables are 1) depression, 2) anxiety, 3) sleep difficulty, and 4) optimism.

As we are interested in the relationship between four continuous variables, this would be best addressed via a multiple correlation. Before we can do this, there are a couple of preliminary steps we need to take.

A lot of the steps are very similar to a simple correlation. So we can refer to the above sections for help if we get unsure.

\emph{Assumptions} The assumptions for a multiple correlation are the same as for a simple correlation, we just need to check for all our variables. The pairs.panels function can be helpful to get the relevant visualisations to check our assumptions for all variables.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairs.panels}\NormalTok{(DataFrameName)}
\end{Highlighting}
\end{Shaded}

Notice that pairs.panel gives us the relevant outputs for all variables (including paritipant number.. which we can see is not normally distributed)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairs.panels}\NormalTok{(df\_sleep)}
\end{Highlighting}
\end{Shaded}

\textbf{Running the multiple correlation} We need a slightly different syntax for multiple correlations:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{correlation}\NormalTok{(DataframeName, }\CommentTok{\# our data}
            \AttributeTok{select =} \FunctionTok{c}\NormalTok{(}\StringTok{"Variable1"}\NormalTok{, }\StringTok{"Variable2"}\NormalTok{, }\StringTok{"Variable3"}\NormalTok{, }\StringTok{"Variable4"}\NormalTok{), }\CommentTok{\# our variables}
             \AttributeTok{method =} \StringTok{"pearson"}\NormalTok{ OR }\StringTok{"spearman"}\NormalTok{,}
            \AttributeTok{p\_adjust =} \StringTok{"bonferroni"}\NormalTok{) }\CommentTok{\# our bonferroni adjustment for multiple comparisons}

\CommentTok{\# Note that we do not specify the direction of our predicted correlation here as some may be positive and others may be negative}
\end{Highlighting}
\end{Shaded}

\textbf{Multiple Comparisons} You may recall from your lectures that conducting multiple statistical tests can be problematic in regards to our alpha level.

When we set our alpha at 0.05 that is setting our Type 1 (False Positive) rate at 5\%. If we then run multiple tests however that rate goes up, with the rate increasing with every test you run. One way to avoid this problem is to use adjusted p-values. The one we're using here is the bonferroni adjustment, which multiplies the p value by the number of comparisons.

\begin{figure}
\centering
\includegraphics{img/Bonferroni.png}
\caption{Bonferroni Adjustment}
\end{figure}

\textbf{Correlation Matrices} We need to visualize our data not only to check our assumptions but also to include in our write-up / results / dissertations. As you may see above the write-up for a multiple correlation can be lengthy/confusing, and a good graphic can help your reader (and you) understand the results more easily.

Today we'll be using the ggcorrplot function. We will learn a lot more about making visualizations in week 9, but for today we will learn how to clearly visualize our correlation results.

If you type in ?ggcorrplot to your console you can see there are many optional arguments you can use to customize your graph.

\textbf{NB} to use ggcorrplot you need to have saved the results of your correlation using the following syntax:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{OutputName }\OtherTok{\textless{}{-}} \FunctionTok{correlation}\NormalTok{(DataframeName, }\CommentTok{\# our data}
            \AttributeTok{select =} \FunctionTok{c}\NormalTok{(}\StringTok{"Variable1"}\NormalTok{, }\StringTok{"Variable2"}\NormalTok{, }\StringTok{"Variable3"}\NormalTok{, }\StringTok{"Variable4"}\NormalTok{), }\CommentTok{\# our variables}
             \AttributeTok{method =} \StringTok{"pearson"}\NormalTok{ OR }\StringTok{"spearman"}\NormalTok{,}
            \AttributeTok{p\_adjust =} \StringTok{"bonferroni"}\NormalTok{) }\CommentTok{\# our bonferroni adjustment for multiple comparisons}

\CommentTok{\# Note that we do not specify the direction of our predicted correlation here as some may be positive and others may be negative}
\end{Highlighting}
\end{Shaded}

\textbf{Power Analyses} Here we are going to learn about how to conduct a power analysis for a correlation.

As you may recall there are some key pieces of information we need for a power analysis, and some specifics that we need for a correlation:

\begin{itemize}
\item
  Alpha level (typically 0.05 in Psychology and the social sciences)
\item
  The minimum correlation size of interest
\item
  Our desired power
\item
  If our test is one or two-tailed (i.e.~do we have a directional or nondirectional hypothesis)
\end{itemize}

The syntax for conducting an apriori statistical power analysis for a simple correlation is the following:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Conduct power analysis for a simple correlation}
\FunctionTok{pwr.r.test}\NormalTok{(}\AttributeTok{r =} \FloatTok{0.2}\NormalTok{, }\CommentTok{\# your expected correlation value}
           \AttributeTok{sig.level =} \FloatTok{0.05}\NormalTok{, }\CommentTok{\# Significance level}
           \AttributeTok{power =} \FloatTok{0.80}\NormalTok{, }\CommentTok{\# Desired power level}
\AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{) }\CommentTok{\# Indicates a two{-}tailed test, \#can be changed to less or greater}
\end{Highlighting}
\end{Shaded}


  \bibliography{book.bib,packages.bib}

\end{document}
